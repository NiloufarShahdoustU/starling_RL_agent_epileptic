{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7001df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# np.random.seed(42)\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.tri as tri\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "import matplotlib.ticker as mticker\n",
    "import itertools\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3bb05db",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 6] The handle is invalid: '27_RL_agent_TDlearn_output_both_param_recovery'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m27_RL_agent_TDlearn_output_both_param_recovery\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m folder_path_participants \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_risk_added_epileptic\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m folder_path_colors_numbers \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m13_RL_agent_TDlearn_output_risk_sensitive/model_behavior\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 6] The handle is invalid: '27_RL_agent_TDlearn_output_both_param_recovery'"
     ]
    }
   ],
   "source": [
    "output_dir = \"27_RL_agent_TDlearn_output_both_param_recovery\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "folder_path_participants = 'data_risk_added_epileptic'\n",
    "folder_path_colors_numbers = '13_RL_agent_TDlearn_output_risk_sensitive/model_behavior'\n",
    "\n",
    "\n",
    "df_participants = []\n",
    "df_colors_numbers = []\n",
    "\n",
    "\n",
    "def find_matching_csv(folder_path, df_list):\n",
    "            for csv_file in os.listdir(folder_path):\n",
    "                if clean_name in csv_file and csv_file.endswith('.csv'):\n",
    "                    csv_path = os.path.join(folder_path, csv_file)\n",
    "                    df_csv = pd.read_csv(csv_path)\n",
    "                    df_list.append(df_csv)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file_name in os.listdir(folder_path_participants):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path_participants, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[df['outcome'].str.lower() != 'na'].reset_index(drop=True) \n",
    "        df_participants.append(df)\n",
    "\n",
    "        clean_name = file_name.removeprefix(\"task_data_\").removesuffix(\".csv\")\n",
    "        find_matching_csv(folder_path_colors_numbers, df_colors_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca226d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_participants:\n",
    "    df['block_type'] = None\n",
    "\n",
    "    df.loc[df['block'] == 1, 'block_type'] = 'uniform'     # Block 1 is uni\n",
    "    df.loc[df['block'] == 4, 'block_type'] = 'mix'     # Block 4 is mix\n",
    "\n",
    "    # For blocks 2 and 3, set based on distribution\n",
    "    df.loc[(df['block'] == 2) & (df['distribution'] == 'low'), 'block_type'] = 'low'\n",
    "    df.loc[(df['block'] == 2) & (df['distribution'] == 'high'), 'block_type'] = 'high'\n",
    "    df.loc[(df['block'] == 3) & (df['distribution'] == 'low'), 'block_type'] = 'low'\n",
    "    df.loc[(df['block'] == 3) & (df['distribution'] == 'high'), 'block_type'] = 'high'\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(df_participants)):\n",
    "    myCard = df_participants[i]['myCard']\n",
    "    yourCard = df_participants[i]['yourCard']\n",
    "    distributions = df_participants[i]['distribution']\n",
    "    block_type = df_participants[i]['block_type']\n",
    "    \n",
    "    for df_list in [ df_colors_numbers]:\n",
    "        df_list[i]['myCard'] = myCard\n",
    "        df_list[i]['yourCard'] = yourCard\n",
    "        df_list[i]['distribution'] = distributions\n",
    "        df_list[i]['block_type'] = block_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01b3673",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_colors_numbers:\n",
    "    df['model_choices'] = df['model_choices'].replace({1: 'arrowup', 0: 'arrowdown'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a491003",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_colors_numbers:\n",
    "    outcomes = []\n",
    "    for i in range(len(df)):\n",
    "        my = df.loc[i, 'myCard']\n",
    "        your = df.loc[i, 'yourCard']\n",
    "        choice = df.loc[i, 'model_choices']\n",
    "        \n",
    "        if ((my > your and choice == \"arrowup\") or (my < your and choice == \"arrow_down\")):\n",
    "            outcomes.append('win')\n",
    "        else:\n",
    "            outcomes.append('lose')\n",
    "    \n",
    "    df['outcome'] = outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578cc339",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [os.path.splitext(file)[0].replace(\"task_data_\", \"\")\n",
    "    for file in os.listdir(folder_path_participants) if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat(df_colors_numbers, ignore_index=True)\n",
    "\n",
    "df_combined = df_combined[df_combined['outcome'].str.lower() != 'na'].reset_index(drop=True)\n",
    " \n",
    "\n",
    "desired_order = [\"uniform\", \"low\", \"high\"]  \n",
    "\n",
    "\n",
    "cards_sorted = sorted(df_combined[\"myCard\"].unique())\n",
    "dist_sorted = [d for d in desired_order if d in df_combined[\"distribution\"].unique()]\n",
    "choice_sorted = sorted(df_combined[\"model_choices\"].unique())\n",
    "\n",
    "\n",
    "card_idx = {card: i for i, card in enumerate(cards_sorted)}\n",
    "dist_idx = {dist: i for i, dist in enumerate(dist_sorted)}\n",
    "choice_idx = {choice: i for i, choice in enumerate(choice_sorted)}\n",
    "\n",
    "\n",
    "matrix_3d = np.zeros((len(cards_sorted), len(dist_sorted), len(choice_sorted)))\n",
    "\n",
    "\n",
    "for _, row in df_combined.iterrows():\n",
    "    i = card_idx[row[\"myCard\"]]-1\n",
    "    j = dist_idx[row[\"distribution\"]]\n",
    "    k = choice_idx[row[\"model_choices\"]]\n",
    "    matrix_3d[i, j, k] += 1  \n",
    "\n",
    "\n",
    "total_per_card_dist = matrix_3d.sum(axis=2, keepdims=True)\n",
    "\n",
    "# compute percentages, avoiding division by zero\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    percentage_matrix = np.divide(matrix_3d, total_per_card_dist, where=total_per_card_dist != 0)\n",
    "\n",
    "# convert to a DataFrame for easy visualization\n",
    "percentage_list = []\n",
    "for i, card in enumerate(cards_sorted):\n",
    "    for j, dist in enumerate(dist_sorted):\n",
    "        for k, choice in enumerate(choice_sorted):\n",
    "            percentage_list.append({\n",
    "                \"myCard\": card,\n",
    "                \"distribution\": dist,  # Now follows \"uniform\", \"low\", \"high\" order\n",
    "                \"model_choices\": choice,\n",
    "                \"percentage\": percentage_matrix[i, j, k]\n",
    "            })\n",
    "\n",
    "df_percentages = pd.DataFrame(percentage_list)\n",
    "df_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb82301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(percentage_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065cd4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = { \"arrowdown\": 0, \"arrowup\": 1}\n",
    "distributions_map = { \"uniform\": 0, \"low\": 1,  \"high\": 2}\n",
    "card_numbers = list(range(1, 10))\n",
    "\n",
    "policy_table = percentage_matrix \n",
    "\n",
    "Q_table_init = np.random.normal(0, 0.1, (len(card_numbers), len(distributions_map), len(actions)))\n",
    "# having a q-table based on the policies\n",
    "Q_table_init = policy_table * np.mean(Q_table_init) \n",
    "Q_table = Q_table_init.copy()\n",
    "\n",
    "#############################################################################################\n",
    "# having a q-table that starts with 0! this was not a good initilization so i changed it.\n",
    "# Q_table = np.zeros((len(distributions_map), len(actions)))  # 3 distributions × 2 actions\n",
    "#############################################################################################\n",
    "\n",
    "print(\"policy: \\n\",np.shape(policy_table))\n",
    "print(\"\\n Q_table: \\n\",np.shape(Q_table))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Q_values, beta):\n",
    "    # this part subtracts the maximum q-value in each row it means each state to improve numerical stability.\n",
    "    # because exxponentials of large numbers can lead to overflow errors, so shifting q-values avoids this problem.\n",
    "    \n",
    "    Q_shifted = Q_values - np.max(Q_values, axis=2, keepdims=True)\n",
    "    exps = np.exp(beta * Q_shifted)\n",
    "    sums = np.sum(exps, axis=2, keepdims=True)\n",
    "    new_probs = exps / sums\n",
    "\n",
    "    return new_probs\n",
    "\n",
    "\n",
    "\n",
    "def train_rescorla_wagner(df, alpha_plus, alpha_minus, beta, Q_init=None):\n",
    "    if Q_init is None:\n",
    "        Q_init = Q_table.copy()\n",
    "    Q_values = Q_init.copy()\n",
    "    q_value_pairs = []\n",
    "    choices = []\n",
    "    predicted_probs = []\n",
    "    distributions = []\n",
    "    card_numbers = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        action = actions[row[\"model_choices\"]] \n",
    "        distribution = distributions_map[row[\"distribution\"]] \n",
    "        card_number = row[\"myCard\"]-1 # since I'm using this as an index! I need to do -1 to make the 1 to 9 cards come to 0 to 8\n",
    "        reward = 0.5 if row[\"outcome\"] == \"win\" else -0.5\n",
    "\n",
    "\n",
    "        probs = softmax(Q_values, beta)\n",
    "        predicted_probs.append(probs[card_number][distribution][action])\n",
    "        \n",
    "        prediction_error = reward - Q_values[card_number][distribution][action]\n",
    "        if prediction_error > 0:    # prediction is less than the real reward\n",
    "            alpha = alpha_plus\n",
    "        else:                       # prediction is more than the real reward\n",
    "            alpha = alpha_minus\n",
    "               \n",
    "        Q_values[card_number][distribution][action] += alpha * prediction_error\n",
    "        \n",
    "        q_value_pairs.append(Q_values.copy())\n",
    "        choices.append(action)\n",
    "        distributions.append(distribution)\n",
    "        card_numbers.append(card_number)\n",
    "        \n",
    "\n",
    "    return np.array(q_value_pairs), np.array(choices), np.array(predicted_probs), np.array(distributions), np.array(card_numbers)\n",
    "\n",
    "\n",
    "# this is for the sake of parallel computing\n",
    "def compute_log_likelihood(alpha_plus, alpha_minus, beta, df_all, Q_table):\n",
    "    Q_init_participant = Q_table.copy()\n",
    "    q_values, choices, predicted_probs, distributions, card_numbers = train_rescorla_wagner(df_all, alpha_plus, alpha_minus, beta, Q_init=Q_init_participant.copy())\n",
    "    \n",
    "    predicted_probs = np.clip(predicted_probs, 1e-6, 1)  # prevent log(0)\n",
    "    log_likelihood = np.sum(np.log(predicted_probs))\n",
    "    \n",
    "    return (alpha_plus, alpha_minus, beta, log_likelihood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93538c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 100\n",
    "# num_of_samples = 1000\n",
    "alpha_min = 0.001\n",
    "alpha_max = 1\n",
    "beta_min = 0\n",
    "beta_max  = 20\n",
    "alpha_plus_samples = np.random.uniform(alpha_min, alpha_max + np.finfo(float).eps, num_of_samples)\n",
    "alpha_minus_samples = np.random.uniform(alpha_min, alpha_max + np.finfo(float).eps, num_of_samples)\n",
    "beta_samples = np.random.uniform(beta_min, beta_max + np.finfo(float).eps, num_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_models = []\n",
    "AIC_models = []\n",
    "best_alpha_plus_models = []\n",
    "best_alpha_minus_models = []\n",
    "best_beta_models = []\n",
    "accuracy_models = []\n",
    "precision_models = []\n",
    "sensitivity_recall_models = []\n",
    "specificity_models = []\n",
    "f1_score_models = []\n",
    "mcFadden_r2_models = []\n",
    "r2_models = []\n",
    "\n",
    "for idx, df_all in enumerate(df_colors_numbers):\n",
    "    print(f\"Processing participant {idx + 1} of {len(df_colors_numbers)}\")\n",
    "    Q_init_participant = Q_table.copy()\n",
    "\n",
    "    df_all = df_all[df_all['outcome'].str.lower() != 'na'].reset_index(drop=True)\n",
    "\n",
    "    results = Parallel(n_jobs=-1, backend='loky')(\n",
    "        delayed(compute_log_likelihood)(alpha_plus, alpha_minus, beta, df_all, Q_init_participant.copy())\n",
    "        for alpha_plus in alpha_plus_samples\n",
    "        for alpha_minus in alpha_minus_samples\n",
    "        for beta in beta_samples\n",
    "    )\n",
    "\n",
    "    alpha_beta_log_likelihood = {}\n",
    "    best_log_likelihood = -np.inf\n",
    "    best_alpha_plus = -1\n",
    "    best_alpha_minus = -1\n",
    "    best_beta = -1\n",
    "\n",
    "    for alpha_plus, alpha_minus, beta, log_likelihood in results:\n",
    "        alpha_beta_log_likelihood[(alpha_plus, alpha_minus, beta)] = log_likelihood\n",
    "        if log_likelihood > best_log_likelihood:\n",
    "            best_log_likelihood = log_likelihood\n",
    "            best_alpha_plus, best_alpha_minus, best_beta = alpha_plus, alpha_minus, beta\n",
    "\n",
    "    results_df = pd.DataFrame(alpha_beta_log_likelihood.keys(), columns=[\"alpha_plus\", \"alpha_minus\", \"beta\"])\n",
    "    results_df[\"log_likelihood\"] = alpha_beta_log_likelihood.values()\n",
    "\n",
    "    \n",
    "    q_values, choices, predicted_probs, distributions, card_numbers = train_rescorla_wagner(df_all, best_alpha_plus, best_alpha_minus, best_beta, Q_init=Q_init_participant.copy())\n",
    "    \n",
    "    \n",
    "    predicted_choices = []\n",
    "    for trial in range(len(card_numbers)):\n",
    "        test_action_probs = softmax(q_values[trial], best_beta)\n",
    "        p_arrowup = test_action_probs[card_numbers[trial]][distributions[trial]][actions[\"arrowup\"]]\n",
    "        p_arrow_down = test_action_probs[card_numbers[trial]][distributions[trial]][actions[\"arrowdown\"]]\n",
    "        # choosing 1 or 0 based on the softmax probabilities:\n",
    "        predicted_choices.append(np.random.choice([1, 0], p=[p_arrowup, p_arrow_down]))\n",
    "\n",
    "\n",
    "    # finding out model total reward based on the model's predicted choices\n",
    "    total_reward = [] \n",
    "    for i in range(len(predicted_choices)):\n",
    "        if len(total_reward)> 0:\n",
    "            last_reward = total_reward[-1]  #  the last reward value\n",
    "        else:\n",
    "            last_reward = 10 # initial reward is $10\n",
    "        \n",
    "        if ((df_all.loc[i, 'myCard'] > df_all.loc[i, 'yourCard'] and predicted_choices[i] == 1) or\n",
    "            (df_all.loc[i, 'myCard'] < df_all.loc[i, 'yourCard'] and predicted_choices[i] == 0)):\n",
    "            total_reward.append(last_reward + 0.5)\n",
    "        else:\n",
    "            total_reward.append(last_reward - 0.5)\n",
    "\n",
    "    \n",
    "    \n",
    "    # confusion matrix:\n",
    "    conf_matrix = confusion_matrix(choices, predicted_choices)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()  # unpacking the confusion matrix\n",
    "    # acc\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    # precision: From the ones that we’ve announced them as up/down, which ones are really up/down?\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    # recall or sensitivity : true positive rate\n",
    "    sensitivity_recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    # specificity : true negative rate\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    # f1 Score\n",
    "    f1_score = 2 * (precision * sensitivity_recall) / (precision + sensitivity_recall) if (precision + sensitivity_recall) != 0 else 0\n",
    "\n",
    "    \n",
    "    # bayes information criterion:\n",
    "    n_trials = len(df_all)\n",
    "    k = 3  # number of free parameters: alpha and beta\n",
    "    BIC = k * np.log(n_trials) - 2 * best_log_likelihood # this is BIC formula based on the log lkelihode I found before\n",
    "\n",
    "        # Akaike  information criterion(AIC):\n",
    "    AIC = 2 * k - 2 * best_log_likelihood \n",
    "\n",
    "    # mcFadden r-squared:\n",
    "    p_null = np.mean(choices)  # probability of choosing \"1\" in the dataset\n",
    "    log_likelihood_null = np.sum(choices * np.log(p_null) + (1 - choices) * np.log(1 - p_null))\n",
    "    mcFadden_r2 = 1 - (best_log_likelihood / log_likelihood_null)\n",
    "\n",
    "    # r-squared\n",
    "    r2 = r2_score(choices, predicted_choices)\n",
    "    \n",
    "    \n",
    "    # saving models evaluation variables:\n",
    "    best_alpha_plus_models.append(best_alpha_plus)\n",
    "    best_alpha_minus_models.append(best_alpha_minus)\n",
    "    best_beta_models.append(best_beta)\n",
    "    BIC_models.append(BIC)\n",
    "    AIC_models.append(AIC)\n",
    "    accuracy_models.append(accuracy)\n",
    "    precision_models.append(precision)\n",
    "    sensitivity_recall_models.append(sensitivity_recall)\n",
    "    specificity_models.append(specificity)\n",
    "    f1_score_models.append(f1_score)\n",
    "    mcFadden_r2_models.append(mcFadden_r2)\n",
    "    r2_models.append(r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6209cd28",
   "metadata": {},
   "source": [
    "# now saving the model evaluation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_evaluation = pd.DataFrame({\n",
    "    \"participants\": participants,\n",
    "    \"best_alpha_plus\": best_alpha_plus_models,\n",
    "    \"best_alpha_minus\": best_alpha_minus_models,\n",
    "    \"best_beta\": best_beta_models,\n",
    "    \"BIC\": BIC_models,\n",
    "    \"AIC\": AIC_models,\n",
    "    \"accuracy\": accuracy_models,\n",
    "    \"precision\": precision_models,\n",
    "    \"sensitivity_recall\": sensitivity_recall_models,\n",
    "    \"specificity\": specificity_models,\n",
    "    \"f1_score\": f1_score_models,\n",
    "    \"mcFadden_r2\": mcFadden_r2_models,\n",
    "    \"r2\": r2_models\n",
    "})\n",
    "\n",
    "file_path = os.path.join(output_dir, \"models_evaluation_risk_sensitive.csv\")\n",
    "df_models_evaluation.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73fb9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f10e808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
