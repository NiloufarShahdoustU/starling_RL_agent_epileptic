{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a6988d",
   "metadata": {},
   "source": [
    "# TD learning; the agent that can see\n",
    "# Remember to check the number of samples for alpha and beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7001df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# np.random.seed(42)\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.tri as tri\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "import matplotlib.ticker as mticker\n",
    "import itertools\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8dd2a",
   "metadata": {},
   "source": [
    "# important directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f147db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'data_risk_added'\n",
    "\n",
    "output_dir_model_evaluation = \"11_RL_agent_TDlearn_output_risk_dualQ\"\n",
    "os.makedirs(output_dir_model_evaluation, exist_ok=True)\n",
    "\n",
    "output_dir_plots = os.path.join(output_dir_model_evaluation, \"plots\")\n",
    "os.makedirs(output_dir_plots, exist_ok=True)\n",
    "\n",
    "output_dir_model_behavior = os.path.join(output_dir_model_evaluation, \"model_behavior\")\n",
    "os.makedirs(output_dir_model_behavior, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "228a8094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 35 participants.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "arrowRT",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "distribution",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "interTrialInterval",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "outcome",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "myCard",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "yourCard",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "spaceRT",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "totalReward",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "trialIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trialType",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "choice",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "block",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timeoutRepeat",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "risk",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2d9b069c-e7f2-4868-aae6-ce04ac5374c4",
       "rows": [
        [
         "0",
         "2609",
         "uniform",
         "789",
         "lose",
         "4",
         "2",
         "1335",
         "9.5",
         "0",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.375"
        ],
        [
         "1",
         "597",
         "uniform",
         "853",
         "win",
         "9",
         "4",
         "1407",
         "10",
         "1",
         "response",
         "arrowup",
         "1",
         "0",
         "0.0"
        ],
        [
         "2",
         "188",
         "uniform",
         "904",
         "win",
         "4",
         "7",
         "1504",
         "10.5",
         "2",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.375"
        ],
        [
         "3",
         "423",
         "uniform",
         "916",
         "win",
         "2",
         "4",
         "1434",
         "11",
         "3",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.125"
        ],
        [
         "4",
         "549",
         "uniform",
         "806",
         "win",
         "5",
         "7",
         "1287",
         "11.5",
         "4",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.5"
        ],
        [
         "5",
         "417",
         "uniform",
         "831",
         "win",
         "2",
         "9",
         "1263",
         "12",
         "5",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.125"
        ],
        [
         "6",
         "397",
         "uniform",
         "857",
         "lose",
         "5",
         "1",
         "1326",
         "11.5",
         "6",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.5"
        ],
        [
         "7",
         "240",
         "uniform",
         "897",
         "win",
         "1",
         "6",
         "1287",
         "12",
         "7",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.0"
        ],
        [
         "8",
         "574",
         "uniform",
         "957",
         "lose",
         "6",
         "9",
         "1269",
         "11.5",
         "8",
         "response",
         "arrowup",
         "1",
         "0",
         "0.375"
        ],
        [
         "9",
         "729",
         "uniform",
         "906",
         "win",
         "8",
         "5",
         "1320",
         "12",
         "9",
         "response",
         "arrowup",
         "1",
         "0",
         "0.125"
        ],
        [
         "10",
         "206",
         "uniform",
         "927",
         "win",
         "1",
         "7",
         "1109",
         "12.5",
         "10",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.0"
        ],
        [
         "11",
         "266",
         "uniform",
         "895",
         "win",
         "1",
         "2",
         "1321",
         "13",
         "11",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.0"
        ],
        [
         "12",
         "258",
         "uniform",
         "758",
         "win",
         "9",
         "2",
         "1377",
         "13.5",
         "12",
         "response",
         "arrowup",
         "1",
         "0",
         "0.0"
        ],
        [
         "13",
         "309",
         "uniform",
         "965",
         "win",
         "4",
         "8",
         "1094",
         "14",
         "13",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.375"
        ],
        [
         "14",
         "479",
         "uniform",
         "930",
         "win",
         "9",
         "5",
         "2966",
         "14.5",
         "14",
         "response",
         "arrowup",
         "1",
         "0",
         "0.0"
        ],
        [
         "15",
         "243",
         "uniform",
         "960",
         "win",
         "2",
         "4",
         "1522",
         "15",
         "15",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.125"
        ],
        [
         "16",
         "613",
         "uniform",
         "886",
         "lose",
         "3",
         "2",
         "1619",
         "14.5",
         "16",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.25"
        ],
        [
         "17",
         "419",
         "uniform",
         "867",
         "win",
         "7",
         "5",
         "1286",
         "15",
         "17",
         "response",
         "arrowup",
         "1",
         "0",
         "0.25"
        ],
        [
         "18",
         "622",
         "uniform",
         "873",
         "win",
         "5",
         "8",
         "1318",
         "15.5",
         "18",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.5"
        ],
        [
         "19",
         "156",
         "uniform",
         "811",
         "win",
         "2",
         "4",
         "1300",
         "16",
         "19",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.125"
        ],
        [
         "20",
         "362",
         "uniform",
         "970",
         "lose",
         "6",
         "8",
         "1366",
         "15.5",
         "20",
         "response",
         "arrowup",
         "1",
         "0",
         "0.375"
        ],
        [
         "21",
         "457",
         "uniform",
         "795",
         "win",
         "8",
         "7",
         "1285",
         "16",
         "21",
         "response",
         "arrowup",
         "1",
         "0",
         "0.125"
        ],
        [
         "22",
         "203",
         "uniform",
         "761",
         "win",
         "1",
         "6",
         "1180",
         "16.5",
         "22",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.0"
        ],
        [
         "23",
         "405",
         "uniform",
         "972",
         "win",
         "7",
         "3",
         "1456",
         "17",
         "23",
         "response",
         "arrowup",
         "1",
         "0",
         "0.25"
        ],
        [
         "24",
         "677",
         "uniform",
         "941",
         "win",
         "9",
         "1",
         "1282",
         "17.5",
         "24",
         "response",
         "arrowup",
         "1",
         "0",
         "0.0"
        ],
        [
         "25",
         "335",
         "uniform",
         "782",
         "lose",
         "3",
         "1",
         "1129",
         "17",
         "25",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.25"
        ],
        [
         "26",
         "170",
         "uniform",
         "983",
         "win",
         "1",
         "9",
         "1304",
         "17.5",
         "26",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.0"
        ],
        [
         "27",
         "517",
         "uniform",
         "785",
         "win",
         "5",
         "6",
         "1688",
         "18",
         "27",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.5"
        ],
        [
         "28",
         "428",
         "uniform",
         "889",
         "win",
         "8",
         "1",
         "1307",
         "18.5",
         "28",
         "response",
         "arrowup",
         "1",
         "0",
         "0.125"
        ],
        [
         "29",
         "457",
         "uniform",
         "884",
         "lose",
         "4",
         "6",
         "1068",
         "18",
         "29",
         "response",
         "arrowup",
         "1",
         "0",
         "0.375"
        ],
        [
         "30",
         "513",
         "uniform",
         "848",
         "win",
         "5",
         "4",
         "1292",
         "18.5",
         "30",
         "response",
         "arrowup",
         "1",
         "0",
         "0.5"
        ],
        [
         "31",
         "1009",
         "uniform",
         "969",
         "win",
         "8",
         "7",
         "1346",
         "19",
         "31",
         "response",
         "arrowup",
         "1",
         "0",
         "0.125"
        ],
        [
         "32",
         "233",
         "uniform",
         "921",
         "win",
         "7",
         "3",
         "1351",
         "19.5",
         "32",
         "response",
         "arrowup",
         "1",
         "0",
         "0.25"
        ],
        [
         "33",
         "834",
         "uniform",
         "890",
         "win",
         "4",
         "9",
         "1480",
         "20",
         "33",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.375"
        ],
        [
         "34",
         "448",
         "uniform",
         "956",
         "win",
         "3",
         "9",
         "1051",
         "20.5",
         "34",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.25"
        ],
        [
         "35",
         "272",
         "uniform",
         "750",
         "win",
         "3",
         "5",
         "1278",
         "21",
         "35",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.25"
        ],
        [
         "36",
         "503",
         "uniform",
         "937",
         "lose",
         "3",
         "1",
         "2152",
         "20.5",
         "36",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.25"
        ],
        [
         "37",
         "214",
         "uniform",
         "999",
         "win",
         "6",
         "2",
         "1298",
         "21",
         "37",
         "response",
         "arrowup",
         "1",
         "0",
         "0.375"
        ],
        [
         "38",
         "377",
         "uniform",
         "888",
         "win",
         "7",
         "5",
         "1279",
         "21.5",
         "38",
         "response",
         "arrowup",
         "1",
         "0",
         "0.25"
        ],
        [
         "39",
         "492",
         "uniform",
         "986",
         "win",
         "2",
         "8",
         "1240",
         "22",
         "39",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.125"
        ],
        [
         "40",
         "350",
         "uniform",
         "832",
         "win",
         "7",
         "3",
         "1161",
         "22.5",
         "40",
         "response",
         "arrowup",
         "1",
         "0",
         "0.25"
        ],
        [
         "41",
         "998",
         "uniform",
         "755",
         "lose",
         "6",
         "3",
         "1321",
         "22",
         "41",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.375"
        ],
        [
         "42",
         "758",
         "uniform",
         "984",
         "win",
         "6",
         "3",
         "1290",
         "22.5",
         "42",
         "response",
         "arrowup",
         "1",
         "0",
         "0.375"
        ],
        [
         "43",
         "726",
         "uniform",
         "989",
         "win",
         "8",
         "6",
         "1354",
         "23",
         "43",
         "response",
         "arrowup",
         "1",
         "0",
         "0.125"
        ],
        [
         "44",
         "276",
         "uniform",
         "847",
         "win",
         "9",
         "8",
         "1285",
         "23.5",
         "44",
         "response",
         "arrowup",
         "1",
         "0",
         "0.0"
        ],
        [
         "45",
         "2132",
         "high",
         "958",
         "lose",
         "8",
         "2",
         "1826",
         "23",
         "90",
         "response",
         "arrowdown",
         "2",
         "0",
         "0.243"
        ],
        [
         "46",
         "600",
         "high",
         "847",
         "lose",
         "6",
         "5",
         "1373",
         "22.5",
         "91",
         "response",
         "arrowdown",
         "2",
         "0",
         "0.385"
        ],
        [
         "47",
         "451",
         "high",
         "903",
         "win",
         "9",
         "4",
         "3047",
         "23",
         "92",
         "response",
         "arrowup",
         "2",
         "0",
         "0.0"
        ],
        [
         "48",
         "866",
         "high",
         "967",
         "win",
         "9",
         "7",
         "1296",
         "23.5",
         "93",
         "response",
         "arrowup",
         "2",
         "0",
         "0.0"
        ],
        [
         "49",
         "472",
         "high",
         "801",
         "win",
         "3",
         "6",
         "1987",
         "24",
         "94",
         "response",
         "arrowdown",
         "2",
         "0",
         "0.071"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 277
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrowRT</th>\n",
       "      <th>distribution</th>\n",
       "      <th>interTrialInterval</th>\n",
       "      <th>outcome</th>\n",
       "      <th>myCard</th>\n",
       "      <th>yourCard</th>\n",
       "      <th>spaceRT</th>\n",
       "      <th>totalReward</th>\n",
       "      <th>trialIndex</th>\n",
       "      <th>trialType</th>\n",
       "      <th>choice</th>\n",
       "      <th>block</th>\n",
       "      <th>timeoutRepeat</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2609</td>\n",
       "      <td>uniform</td>\n",
       "      <td>789</td>\n",
       "      <td>lose</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1335</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>597</td>\n",
       "      <td>uniform</td>\n",
       "      <td>853</td>\n",
       "      <td>win</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1407</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowup</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188</td>\n",
       "      <td>uniform</td>\n",
       "      <td>904</td>\n",
       "      <td>win</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1504</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423</td>\n",
       "      <td>uniform</td>\n",
       "      <td>916</td>\n",
       "      <td>win</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1434</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>549</td>\n",
       "      <td>uniform</td>\n",
       "      <td>806</td>\n",
       "      <td>win</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1287</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>761</td>\n",
       "      <td>high</td>\n",
       "      <td>913</td>\n",
       "      <td>win</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1382</td>\n",
       "      <td>80</td>\n",
       "      <td>125</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>596</td>\n",
       "      <td>low</td>\n",
       "      <td>921</td>\n",
       "      <td>win</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1318</td>\n",
       "      <td>80.5</td>\n",
       "      <td>83</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowup</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>414</td>\n",
       "      <td>low</td>\n",
       "      <td>950</td>\n",
       "      <td>win</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1335</td>\n",
       "      <td>81</td>\n",
       "      <td>77</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1371</td>\n",
       "      <td>uniform</td>\n",
       "      <td>842</td>\n",
       "      <td>win</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1615</td>\n",
       "      <td>81.5</td>\n",
       "      <td>35</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowup</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>524</td>\n",
       "      <td>low</td>\n",
       "      <td>897</td>\n",
       "      <td>win</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1299</td>\n",
       "      <td>82</td>\n",
       "      <td>71</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowup</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrowRT distribution  interTrialInterval outcome  myCard  yourCard  \\\n",
       "0      2609      uniform                 789    lose       4         2   \n",
       "1       597      uniform                 853     win       9         4   \n",
       "2       188      uniform                 904     win       4         7   \n",
       "3       423      uniform                 916     win       2         4   \n",
       "4       549      uniform                 806     win       5         7   \n",
       "..      ...          ...                 ...     ...     ...       ...   \n",
       "272     761         high                 913     win       7         8   \n",
       "273     596          low                 921     win       4         3   \n",
       "274     414          low                 950     win       2         7   \n",
       "275    1371      uniform                 842     win       6         4   \n",
       "276     524          low                 897     win       6         1   \n",
       "\n",
       "     spaceRT totalReward  trialIndex trialType     choice  block  \\\n",
       "0       1335         9.5           0  response  arrowdown      1   \n",
       "1       1407          10           1  response    arrowup      1   \n",
       "2       1504        10.5           2  response  arrowdown      1   \n",
       "3       1434          11           3  response  arrowdown      1   \n",
       "4       1287        11.5           4  response  arrowdown      1   \n",
       "..       ...         ...         ...       ...        ...    ...   \n",
       "272     1382          80         125  response  arrowdown      4   \n",
       "273     1318        80.5          83  response    arrowup      4   \n",
       "274     1335          81          77  response  arrowdown      4   \n",
       "275     1615        81.5          35  response    arrowup      4   \n",
       "276     1299          82          71  response    arrowup      4   \n",
       "\n",
       "     timeoutRepeat   risk  \n",
       "0                0  0.375  \n",
       "1                0  0.000  \n",
       "2                0  0.375  \n",
       "3                0  0.125  \n",
       "4                0  0.500  \n",
       "..             ...    ...  \n",
       "272              0  0.447  \n",
       "273              0  0.385  \n",
       "274              0  0.243  \n",
       "275              0  0.375  \n",
       "276              0  0.146  \n",
       "\n",
       "[277 rows x 14 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = [pd.read_excel(os.path.join(folder_path, file)) for file in os.listdir(folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "n_participant = len(dataframes)\n",
    "print(f\"there are {n_participant} participants.\")\n",
    "dataframes[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e57510",
   "metadata": {},
   "source": [
    "### I want to make participant file name for the model_evaluation.csv and that is I'm gonna take each data name task_data_07_11_2024_17_23_43.xlsx and extract \"07_11_2024_17_23_43\" and this should be the participant name in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "655a0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [os.path.splitext(file)[0].replace(\"task_data_\", \"\")\n",
    "    for file in os.listdir(folder_path) if file.endswith('.xlsx')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec4cf94",
   "metadata": {},
   "source": [
    "# policy initilization for the model\n",
    "now I need to find the prior policy amounts. for that I am going to put the percentage of downarrow and up arrow for each distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc4d584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined = pd.concat(dataframes, ignore_index=True)\n",
    "# df_combined = df_combined[df_combined['outcome'].str.lower() != 'na'].reset_index(drop=True)  \n",
    "\n",
    "# count_df = df_combined.pivot_table(index=\"distribution\", columns=\"choice\", aggfunc=\"size\", fill_value=0)\n",
    "# policy_initialization_df = count_df.div(count_df.sum(axis=1), axis=0)\n",
    "# policy_initialization_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "065cd4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = { \"arrowdown\": 0, \"arrowup\": 1}\n",
    "distributions_map = { \"uniform\": 0, \"low\": 1,  \"high\": 2}\n",
    "\n",
    "# policy_table = policy_initialization_df.rename(index=distributions_map, columns=actions).sort_index().to_numpy()\n",
    "\n",
    "Q_table_init = np.random.normal(0, 0.1, (len(distributions_map), len(actions)))\n",
    "\n",
    "\n",
    "# having a q-table based on the policies\n",
    "# Q_table_init = policy_table * np.mean(Q_table_init) \n",
    "Q_table = Q_table_init.copy()\n",
    "\n",
    "# having a q-table that starts with 0!\n",
    "# Q_table = np.zeros((len(distributions_map), len(actions)))  # 3 distributions × 2 actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25b4d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Q_values, beta):    \n",
    "    # this part subtracts the maximum q-value in each row it means each state to improve numerical stability.\n",
    "    # because exxponentials of large numbers can lead to overflow errors, so shifting q-values avoids this problem.\n",
    "    \n",
    "    Q_shifted = Q_values - np.max(Q_values, axis=1, keepdims=True)\n",
    "    exps = np.exp(beta * Q_shifted)\n",
    "    sums = np.sum(exps, axis=1, keepdims=True)\n",
    "    new_probs = exps / sums\n",
    "\n",
    "    return new_probs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_dualQ_risk_sensitive(df, alpha_r, alpha_s, beta, eta, Qr_init=None, Qs_init=None):\n",
    "    if Qr_init is None:\n",
    "        Qr_init = Q_table.copy()\n",
    "    if Qs_init is None:\n",
    "        Qs_init = Q_table.copy()\n",
    "\n",
    "    Qr = Qr_init.copy()\n",
    "    Qs = Qs_init.copy()\n",
    "\n",
    "    q_value_pairs = []\n",
    "    choices = []\n",
    "    predicted_probs = []\n",
    "    distributions = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        action = actions[row[\"choice\"]]\n",
    "        distribution = distributions_map[row[\"distribution\"]]\n",
    "        reward = 0.5 if row[\"outcome\"] == \"win\" else -0.5\n",
    "        risk = row[\"risk\"]  \n",
    "\n",
    "        Q_combined = Qr - eta * Qs\n",
    "        probs = softmax(Q_combined, beta)\n",
    "        predicted_probs.append(probs[distribution][action])\n",
    "\n",
    "        Qr[distribution][action] += alpha_r * (reward - Qr[distribution][action])\n",
    "        Qs[distribution][action] += alpha_s * (risk - Qs[distribution][action])\n",
    "\n",
    "        q_value_pairs.append(Q_combined.copy())\n",
    "        choices.append(action)\n",
    "        distributions.append(distribution)\n",
    "\n",
    "    return np.array(q_value_pairs), np.array(choices), np.array(predicted_probs), np.array(distributions)\n",
    "\n",
    "\n",
    "\n",
    "def compute_log_likelihood(alpha_r, alpha_s, beta, eta, df_all):\n",
    "    q_values, choices, predicted_probs, distributions = train_dualQ_risk_sensitive(\n",
    "        df_all, alpha_r, alpha_s, beta, eta\n",
    "    )\n",
    "    predicted_probs = np.clip(predicted_probs, 1e-6, 1)\n",
    "    log_likelihood = np.sum(np.log(predicted_probs))\n",
    "    return (alpha_r, alpha_s, beta, eta, log_likelihood)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a1e292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 30\n",
    "alpha_min = 0\n",
    "alpha_max = 1\n",
    "beta_min = 0\n",
    "beta_max  = 10\n",
    "eta_min = -1\n",
    "eta_max = 1\n",
    "\n",
    "alpha_r_samples = np.random.uniform(alpha_min, alpha_max + np.finfo(float).eps, num_of_samples)\n",
    "alpha_s_samples = np.random.uniform(alpha_min, alpha_max + np.finfo(float).eps, num_of_samples)\n",
    "beta_samples = np.random.uniform(beta_min, beta_max + np.finfo(float).eps, num_of_samples)\n",
    "eta_samples = np.random.uniform(eta_min, eta_max + np.finfo(float).eps, num_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a0f6378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_07_11_2024_17_23_43.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_08_11_2024_13_03_29.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_11_11_2024_16_46_44.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_12_11_2024_00_15_17.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_13_11_2024_10_46_21.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_13_11_2024_14_45_52.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_14_11_2024_21_46_47.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_15_11_2024_11_43_48.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_17_11_2024_15_25_39.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_17_11_2024_23_57_47.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_18_03_2025_13_12_31.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_18_03_2025_20_59_56.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_18_11_2024_13_31_43.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_18_11_2024_15_43_17.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_19_11_2024_14_28_20.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_19_11_2024_17_03_01.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_19_11_2024_19_42_32.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_20_11_2024_09_23_29.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_20_11_2024_14_51_17.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_20_11_2024_15_14_56.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_20_11_2024_15_41_35.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_20_11_2024_16_58_23.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_22_03_2025_00_10_37.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_22_11_2024_12_34_30.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_22_11_2024_14_36_42.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_22_11_2024_15_19_47.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_25_11_2024_07_37_11.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_25_11_2024_12_11_10.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_25_11_2024_18_41_38.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_25_11_2024_20_12_41.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_26_03_2025_16_21_25.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_26_11_2024_10_53_23.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_26_11_2024_14_31_40.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_28_11_2024_12_21_16.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ\\plots\\plot_28_11_2024_22_38_25.pdf\n"
     ]
    }
   ],
   "source": [
    "BIC_models = []\n",
    "AIC_models = []\n",
    "best_alpha_r_models = []\n",
    "best_alpha_s_models = []\n",
    "best_eta_models = []\n",
    "best_beta_models = []\n",
    "accuracy_models = []\n",
    "precision_models = []\n",
    "sensitivity_recall_models = []\n",
    "specificity_models = []\n",
    "f1_score_models = []\n",
    "mcFadden_r2_models = []\n",
    "r2_models = []\n",
    "\n",
    "for idx, df_all in enumerate(dataframes):\n",
    "    \n",
    "    df_all = df_all[df_all['outcome'].str.lower() != 'na'].reset_index(drop=True)  \n",
    "\n",
    "    \n",
    "    Q_init_participant = Q_table.copy()\n",
    "\n",
    "    best_alpha, best_beta = None, None\n",
    "    best_log_likelihood = -np.inf\n",
    "\n",
    "\n",
    "    alpha_beta_log_likelihood = {}\n",
    "\n",
    "\n",
    "    # finding alpha beta in parallel way\n",
    "    results = Parallel(n_jobs=-1, backend='loky')(\n",
    "    delayed(compute_log_likelihood)(alpha_r, alpha_s, beta, eta, df_all)\n",
    "    for alpha_r in alpha_r_samples\n",
    "    for alpha_s in alpha_s_samples\n",
    "    for beta in beta_samples\n",
    "    for eta in eta_samples)\n",
    "\n",
    "\n",
    "    alpha_beta_log_likelihood = {}\n",
    "    best_log_likelihood = -np.inf\n",
    "\n",
    "\n",
    "    for alpha_r, alpha_s, beta, eta, log_likelihood in results:\n",
    "        if log_likelihood > best_log_likelihood:\n",
    "            best_log_likelihood = log_likelihood\n",
    "            best_alpha_r = alpha_r\n",
    "            best_alpha_s = alpha_s\n",
    "            best_beta = beta\n",
    "            best_eta = eta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #  model prediction \n",
    "    \n",
    "    # this is not model's choices, it's human choices, you need to save model predicted choices using q-values\n",
    "    q_values, choices, predicted_probs, distributions  = train_dualQ_risk_sensitive(df_all, best_alpha_r, best_alpha_s, best_beta, best_eta)\n",
    "    # now we need to find out the predicted choices of the model:\n",
    "    \n",
    "\n",
    "    ###################################################################################################################\n",
    "    # now we need to find out the predicted choices of the model:\n",
    "    # predicted_choices = []\n",
    "    # for trial in range(len(distributions)):  \n",
    "    #     if q_values[trial][distributions[trial]][actions[\"arrowup\"]] > q_values[trial][distributions[trial]][actions[\"arrowdown\"]]:\n",
    "    #         predicted_choices.append(1)\n",
    "    #     else:\n",
    "    #         predicted_choices.append(0)\n",
    "\n",
    "\n",
    "    # the code above was not correct!! because we're using softmax policy in the training process but here we're ONLY\n",
    "    # using greedy way of choosing best actions! so here is the corect code:\n",
    "    ###################################################################################################################\n",
    "\n",
    "    predicted_choices = []\n",
    "    for trial in range(len(distributions)):  \n",
    "        test_action_probs = softmax(q_values[trial], best_beta)\n",
    "        p_arrowup = test_action_probs[distributions[trial]][actions[\"arrowup\"]]\n",
    "        p_arrow_down = test_action_probs[distributions[trial]][actions[\"arrowdown\"]]\n",
    "        # choosing 1 or 0 based on the softmax probabilities:\n",
    "        predicted_choices.append(np.random.choice([1, 0], p=[p_arrowup, p_arrow_down]))\n",
    "\n",
    "\n",
    "    # finding out model total reward based on the model's predicted choices\n",
    "    total_reward = [] \n",
    "    for i in range(len(predicted_choices)):\n",
    "        if len(total_reward)> 0:\n",
    "            last_reward = total_reward[-1]  #  the last reward value\n",
    "        else:\n",
    "            last_reward = 10 # initial reward is $10\n",
    "        \n",
    "        if ((df_all.loc[i, 'myCard'] > df_all.loc[i, 'yourCard'] and predicted_choices[i] == 1) or\n",
    "            (df_all.loc[i, 'myCard'] < df_all.loc[i, 'yourCard'] and predicted_choices[i] == 0)):\n",
    "            total_reward.append(last_reward + 0.5)\n",
    "        else:\n",
    "            total_reward.append(last_reward - 0.5)\n",
    "    \n",
    "    \n",
    "       # confusion matrix:\n",
    "    conf_matrix = confusion_matrix(choices, predicted_choices)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()  # unpacking the confusion matrix\n",
    "    # acc\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    # precision: From the ones that we’ve announced them as up/down, which ones are really up/down?\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    # recall or sensitivity : true positive rate\n",
    "    sensitivity_recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    # specificity : true negative rate\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    # f1 Score\n",
    "    f1_score = 2 * (precision * sensitivity_recall) / (precision + sensitivity_recall) if (precision + sensitivity_recall) != 0 else 0\n",
    "\n",
    "    \n",
    "    # bayes information criterion:\n",
    "    n_trials = len(df_all)\n",
    "    k = 4  # number of free parameters: alpha and beta\n",
    "    BIC = k * np.log(n_trials) - 2 * best_log_likelihood # this is BIC formula based on the log lkelihode I found before\n",
    "\n",
    "\n",
    "    # Akaike  information criterion(AIC):\n",
    "    AIC = 2 * k - 2 * best_log_likelihood \n",
    "\n",
    "    # mcFadden r-squared:\n",
    "    p_null = np.mean(choices)  # probability of choosing \"1\" in the dataset\n",
    "    log_likelihood_null = np.sum(choices * np.log(p_null) + (1 - choices) * np.log(1 - p_null))\n",
    "    mcFadden_r2 = 1 - (best_log_likelihood / log_likelihood_null)\n",
    "\n",
    "    # r-squared\n",
    "    r2 = r2_score(choices, predicted_choices)\n",
    "    \n",
    " \n",
    "    # saving models evaluation variables:\n",
    "    best_alpha_r_models.append(best_alpha_r)\n",
    "    best_alpha_s_models.append(best_alpha_s)\n",
    "    best_eta_models.append(best_eta)\n",
    "    best_beta_models.append(best_beta)\n",
    "    BIC_models.append(BIC)\n",
    "    AIC_models.append(AIC)\n",
    "    accuracy_models.append(accuracy)\n",
    "    precision_models.append(precision)\n",
    "    sensitivity_recall_models.append(sensitivity_recall)\n",
    "    specificity_models.append(specificity)\n",
    "    f1_score_models.append(f1_score)\n",
    "    mcFadden_r2_models.append(mcFadden_r2)\n",
    "    r2_models.append(r2)\n",
    "\n",
    "  \n",
    "    ###########################################################################################\n",
    "    ## visulization\n",
    "    ###########################################################################################\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    heatmap_cmap_color = mcolors.LinearSegmentedColormap.from_list(\"warm_red\", [\"#fff5e6\", \"#ff5733\"])\n",
    "    sns.heatmap(\n",
    "        conf_matrix, annot=True, fmt=\"d\", cmap=heatmap_cmap_color,\n",
    "        xticklabels=[\"arrowdown\", \"arrowup\"], \n",
    "        yticklabels=[\"arrowdown\", \"arrowup\"], \n",
    "        ax=ax, \n",
    "        cbar=False\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"prediction\", fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(\"true label\", fontsize=14, fontweight='bold')\n",
    "    ax.set_title(\"confusion matrix\", fontsize=16, fontweight='bold')\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "\n",
    "#############################################\n",
    "    # saving figures\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.9]) \n",
    "    fig.suptitle(f'participant {idx}', fontsize=18, fontweight='bold', y=0.95)\n",
    "\n",
    "    filename = os.path.join(output_dir_plots, f\"plot_{participants[idx]}.pdf\")\n",
    "    plt.savefig(filename, format='pdf')\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"saved: {filename}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "    # saving model behavior\n",
    "    q_values_reshaped = [q_values[i].tolist() for i in range(n_trials)]  # convert each (9,3,2) array into a list format\n",
    "\n",
    "    # print(\"Shape of predicted_choices:\", np.shape(predicted_choices))\n",
    "    # print(\"Shape of choices:\", np.shape(choices))\n",
    "    # print(\"Shape of total_reward:\", np.shape(total_reward))\n",
    "    # print(\"Shape of q_values_reshaped:\", np.shape(q_values_reshaped))\n",
    "\n",
    "    df_model_behavior = pd.DataFrame({\n",
    "        \"model_choices\": predicted_choices,\n",
    "        \"participant_choices\": choices,\n",
    "        \"model_total_reward\": total_reward,\n",
    "        \"participant_total_reward\": df_all[\"totalReward\"],\n",
    "        \"q_val\": q_values_reshaped  \n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    file_path = os.path.join(output_dir_model_behavior, f\"model_behavior_{participants[idx]}.csv\")\n",
    "    df_model_behavior.to_csv(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf9815f",
   "metadata": {},
   "source": [
    "# now saving the model evaluation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fa0bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_evaluation = pd.DataFrame({\n",
    "    \"participants\": participants,\n",
    "    \"best_alpha_r\": best_alpha_r_models,\n",
    "    \"best_alpha_s\": best_alpha_s_models,\n",
    "    \"best_beta\": best_beta_models,\n",
    "    \"best_eta\": best_eta_models,\n",
    "    \"BIC\": BIC_models,\n",
    "    \"AIC\": AIC_models,\n",
    "    \"accuracy\": accuracy_models,\n",
    "    \"precision\": precision_models,\n",
    "    \"sensitivity_recall\": sensitivity_recall_models,\n",
    "    \"specificity\": specificity_models,\n",
    "    \"f1_score\": f1_score_models,\n",
    "    \"mcFadden_r2\": mcFadden_r2_models,\n",
    "    \"r2\": r2_models\n",
    "})\n",
    "\n",
    "file_path = os.path.join(output_dir_model_evaluation, \"models_evaluation.csv\")\n",
    "df_models_evaluation.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b094a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74688048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bebc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acf4011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
