{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a6988d",
   "metadata": {},
   "source": [
    "# win stay lose shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7001df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "np.random.seed(42)\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.tri as tri\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "import matplotlib.ticker as mticker\n",
    "import itertools\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d263cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"27_RL_agent_TDlearn_output_both_param_recovery\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "folder_path_participants = 'data_risk_added_epileptic'\n",
    "folder_path_colors_numbers = '13_RL_agent_TDlearn_output_wsls/model_behavior'\n",
    "\n",
    "\n",
    "df_participants = []\n",
    "df_colors_numbers = []\n",
    "\n",
    "\n",
    "def find_matching_csv(folder_path, df_list):\n",
    "            for csv_file in os.listdir(folder_path):\n",
    "                if clean_name in csv_file and csv_file.endswith('.csv'):\n",
    "                    csv_path = os.path.join(folder_path, csv_file)\n",
    "                    df_csv = pd.read_csv(csv_path)\n",
    "                    df_list.append(df_csv)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file_name in os.listdir(folder_path_participants):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path_participants, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[df['outcome'].str.lower() != 'na'].reset_index(drop=True) \n",
    "        df_participants.append(df)\n",
    "\n",
    "        clean_name = file_name.removeprefix(\"task_data_\").removesuffix(\".csv\")\n",
    "        find_matching_csv(folder_path_colors_numbers, df_colors_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "655a0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_participants:\n",
    "    df['block_type'] = None\n",
    "\n",
    "    df.loc[df['block'] == 1, 'block_type'] = 'uniform'     # Block 1 is uni\n",
    "    df.loc[df['block'] == 4, 'block_type'] = 'mix'     # Block 4 is mix\n",
    "\n",
    "    # For blocks 2 and 3, set based on distribution\n",
    "    df.loc[(df['block'] == 2) & (df['distribution'] == 'low'), 'block_type'] = 'low'\n",
    "    df.loc[(df['block'] == 2) & (df['distribution'] == 'high'), 'block_type'] = 'high'\n",
    "    df.loc[(df['block'] == 3) & (df['distribution'] == 'low'), 'block_type'] = 'low'\n",
    "    df.loc[(df['block'] == 3) & (df['distribution'] == 'high'), 'block_type'] = 'high'\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(df_participants)):\n",
    "    myCard = df_participants[i]['myCard']\n",
    "    yourCard = df_participants[i]['yourCard']\n",
    "    distributions = df_participants[i]['distribution']\n",
    "    block_type = df_participants[i]['block_type']\n",
    "    \n",
    "    for df_list in [ df_colors_numbers]:\n",
    "        df_list[i]['myCard'] = myCard\n",
    "        df_list[i]['yourCard'] = yourCard\n",
    "        df_list[i]['distribution'] = distributions\n",
    "        df_list[i]['block_type'] = block_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa610ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_colors_numbers:\n",
    "    df['model_choices'] = df['model_choices'].replace({1: 'arrowup', 0: 'arrowdown'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ea5a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_colors_numbers:\n",
    "    outcomes = []\n",
    "    for i in range(len(df)):\n",
    "        my = df.loc[i, 'myCard']\n",
    "        your = df.loc[i, 'yourCard']\n",
    "        choice = df.loc[i, 'model_choices']\n",
    "        \n",
    "        if ((my > your and choice == \"arrowup\") or (my < your and choice == \"arrow_down\")):\n",
    "            outcomes.append('win')\n",
    "        else:\n",
    "            outcomes.append('lose')\n",
    "    \n",
    "    df['outcome'] = outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2478c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [os.path.splitext(file)[0].replace(\"task_data_\", \"\")\n",
    "    for file in os.listdir(folder_path_participants) if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f24042c",
   "metadata": {},
   "source": [
    "### alpha = p_stay_after_win\n",
    "### beta = p_shift_after_lose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a1e292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 100\n",
    "# num_of_samples = 1000\n",
    "alpha_min = 0\n",
    "alpha_max = 1\n",
    "beta_min = 0\n",
    "beta_max  = 1\n",
    "alpha_samples = np.random.uniform(alpha_min, alpha_max + np.finfo(float).eps, num_of_samples)\n",
    "beta_samples = np.random.uniform(beta_min, beta_max + np.finfo(float).eps, num_of_samples)\n",
    "\n",
    "actions = { \"arrowdown\": 0, \"arrowup\": 1}\n",
    "distributions_map = { \"uniform\": 0, \"low\": 1,  \"high\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab95c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the probability that the model assigns to the actual choice the participant made on a given trial, based on the model's current parameters and the outcome of the previous trial.\n",
    "\n",
    "def get_wsls_probability(prev_choice, current_choice, prev_reward, p_stay_win, p_shift_loss):\n",
    "    if prev_reward > 0:  # win\n",
    "        return p_stay_win if current_choice == prev_choice else 1 - p_stay_win\n",
    "    else:  # lose\n",
    "        return p_shift_loss if current_choice != prev_choice else 1 - p_shift_loss\n",
    "\n",
    "\n",
    "\n",
    "def simulate_wsls_choices(prev_choice, rewards, p_stay_win, p_shift_loss):\n",
    "    n_trials = len(rewards)\n",
    "    choices = []\n",
    "    for t in range(n_trials):             \n",
    "        if t > 0:                          \n",
    "            prev_reward = rewards[t-1]\n",
    "            stay_prob = p_stay_win if prev_reward > 0 else 1 - p_shift_loss\n",
    "            switch_prob = 1 - stay_prob\n",
    "            probs = [stay_prob, switch_prob] if prev_choice == 0 else [switch_prob, stay_prob]\n",
    "            prev_choice = np.random.choice([0,1], p=probs)\n",
    "        choices.append(prev_choice)\n",
    "    return np.array(choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3bebc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing participant 1 of 7\n",
      "Processing participant 2 of 7\n",
      "Processing participant 3 of 7\n",
      "Processing participant 4 of 7\n",
      "Processing participant 5 of 7\n",
      "Processing participant 6 of 7\n",
      "Processing participant 7 of 7\n"
     ]
    }
   ],
   "source": [
    "BIC_models = []\n",
    "AIC_models = []\n",
    "best_alpha_models = []\n",
    "best_beta_models = []\n",
    "accuracy_models = []\n",
    "precision_models = []\n",
    "sensitivity_recall_models = []\n",
    "specificity_models = []\n",
    "f1_score_models = []\n",
    "mcFadden_r2_models = []\n",
    "r2_models = []\n",
    "\n",
    "\n",
    "\n",
    "# participants loop\n",
    "for idx, df_all in enumerate(df_colors_numbers):\n",
    "    print(f\"Processing participant {idx + 1} of {len(df_colors_numbers)}\")\n",
    "    df_all = df_all[df_all['outcome'].str.lower() != 'na'].reset_index(drop=True)\n",
    "    rewards = df_all['outcome'].apply(lambda x: 1 if x.lower() == 'win' else 0).values\n",
    "    true_choices = df_all['model_choices'].map(actions).values\n",
    "    trials_myCard = df_all[\"myCard\"]\n",
    "    trials_myCard_unique = df_all[\"myCard\"].unique()\n",
    "    trials_distribution = df_all['distribution'].map(distributions_map).values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    best_alpha, best_beta = None, None\n",
    "    best_log_likelihood = -np.inf\n",
    "\n",
    "    results = []\n",
    "    for alpha in alpha_samples:\n",
    "        for beta in beta_samples:\n",
    "            log_likelihood = 0\n",
    "\n",
    "            prev_choice = np.full((len(distributions_map), len(trials_myCard_unique)), np.nan)\n",
    "\n",
    "            prev_choice[trials_distribution[0], trials_myCard[0]-1] = true_choices[0]\n",
    "\n",
    "            prev_reward = np.full((len(distributions_map), len(trials_myCard_unique)), np.nan)\n",
    "\n",
    "\n",
    "            for t in range(1, len(rewards)): # trial by trial\n",
    "\n",
    "                prev_reward[trials_distribution[t - 1], trials_myCard[t - 1]-1] = rewards[t - 1]\n",
    "\n",
    "        \n",
    "                prob = get_wsls_probability(prev_choice[trials_distribution[t - 1],trials_myCard[t - 1]-1], true_choices[t], prev_reward[trials_distribution[t - 1], trials_myCard[t - 1]-1], alpha, beta)\n",
    "                prob = np.clip(prob, 1e-6, 1 - 1e-6) # avoid log(0)\n",
    "                log_likelihood += np.log(prob)\n",
    "                prev_choice[trials_distribution[t - 1], trials_myCard[t]-1] = true_choices[t]\n",
    "            \n",
    "            \n",
    "            results.append((alpha, beta, log_likelihood))\n",
    "                \n",
    "\n",
    "            if log_likelihood > best_log_likelihood:\n",
    "                best_alpha, best_beta = alpha, beta\n",
    "                best_log_likelihood = log_likelihood\n",
    "\n",
    "\n",
    "\n",
    "    best_predicted_choices = simulate_wsls_choices(true_choices[0], rewards, best_alpha, best_beta)\n",
    "\n",
    "    conf_matrix = confusion_matrix(true_choices, best_predicted_choices)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP) if (TP + FP) else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) else 0\n",
    "    specificity = TN / (TN + FP) if (TN + FP) else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "    n_trials = len(df_all)\n",
    "    k = 2\n",
    "    BIC = k * np.log(n_trials) - 2 * best_log_likelihood\n",
    "    AIC = 2 * k - 2 * best_log_likelihood\n",
    "    p_null = np.mean(true_choices)\n",
    "    p_null  = np.clip(p_null, 1e-6, 1 - 1e-6)\n",
    "    log_likelihood_null = np.sum(true_choices * np.log(p_null) + (1 - true_choices) * np.log(1 - p_null))\n",
    "    mcFadden_r2 = 1 - (best_log_likelihood / log_likelihood_null)\n",
    "    r2 = r2_score(true_choices, best_predicted_choices)\n",
    "\n",
    "    best_alpha_models.append(best_alpha)\n",
    "    best_beta_models.append(best_beta)\n",
    "    BIC_models.append(BIC)\n",
    "    AIC_models.append(AIC)\n",
    "    accuracy_models.append(accuracy)\n",
    "    precision_models.append(precision)\n",
    "    sensitivity_recall_models.append(recall)\n",
    "    specificity_models.append(specificity)\n",
    "    f1_score_models.append(f1)\n",
    "    mcFadden_r2_models.append(mcFadden_r2)\n",
    "    r2_models.append(r2)\n",
    "\n",
    "\n",
    "\n",
    "    total_reward = []\n",
    "    for i in range(len(best_predicted_choices)):\n",
    "        last_reward = total_reward[-1] if total_reward else 10\n",
    "        if ((df_all.loc[i, 'myCard'] > df_all.loc[i, 'yourCard'] and best_predicted_choices[i] == 1) or\n",
    "            (df_all.loc[i, 'myCard'] < df_all.loc[i, 'yourCard'] and best_predicted_choices[i] == 0)):\n",
    "            total_reward.append(last_reward + 0.5)\n",
    "        else:\n",
    "            total_reward.append(last_reward - 0.5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b7b7d1",
   "metadata": {},
   "source": [
    "# now saving the model evaluation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db005ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame({\n",
    "    \"participants\": participants,\n",
    "    \"best_alpha\": best_alpha_models,\n",
    "    \"best_beta\": best_beta_models,\n",
    "    \"BIC\": BIC_models,\n",
    "    \"AIC\": AIC_models,\n",
    "    \"accuracy\": accuracy_models,\n",
    "    \"precision\": precision_models,\n",
    "    \"sensitivity_recall\": sensitivity_recall_models,\n",
    "    \"specificity\": specificity_models,\n",
    "    \"f1_score\": f1_score_models,\n",
    "    \"mcFadden_r2\": mcFadden_r2_models,\n",
    "    \"r2\": r2_models\n",
    "})\n",
    "\n",
    "summary_path = os.path.join(output_dir, \"models_evaluation_wsls.csv\")\n",
    "summary_df.to_csv(summary_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae35fb9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7bf81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
