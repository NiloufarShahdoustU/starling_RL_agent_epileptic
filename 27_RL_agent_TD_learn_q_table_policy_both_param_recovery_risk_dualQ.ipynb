{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7001df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# np.random.seed(42)\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.tri as tri\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "import matplotlib.ticker as mticker\n",
    "import itertools\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33a1a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"27_RL_agent_TDlearn_output_both_param_recovery\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "folder_path_participants = 'data_risk_added'\n",
    "folder_path_colors_numbers = '13_RL_agent_TDlearn_output_risk_dualQ/model_behavior'\n",
    "\n",
    "\n",
    "df_participants = []\n",
    "df_colors_numbers = []\n",
    "\n",
    "\n",
    "def find_matching_csv(folder_path, df_list):\n",
    "            for csv_file in os.listdir(folder_path):\n",
    "                if clean_name in csv_file and csv_file.endswith('.csv'):\n",
    "                    csv_path = os.path.join(folder_path, csv_file)\n",
    "                    df_csv = pd.read_csv(csv_path)\n",
    "                    df_list.append(df_csv)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file_name in os.listdir(folder_path_participants):\n",
    "    if file_name.endswith('.xlsx'):\n",
    "        file_path = os.path.join(folder_path_participants, file_name)\n",
    "        df = pd.read_excel(file_path)\n",
    "        df = df[df['outcome'].str.lower() != 'na'].reset_index(drop=True) \n",
    "        df_participants.append(df)\n",
    "\n",
    "        clean_name = file_name.removeprefix(\"task_data_\").removesuffix(\".xlsx\")\n",
    "        find_matching_csv(folder_path_colors_numbers, df_colors_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67751ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_participants:\n",
    "    df['block_type'] = None\n",
    "\n",
    "    df.loc[df['block'] == 1, 'block_type'] = 'uniform'     # Block 1 is uni\n",
    "    df.loc[df['block'] == 4, 'block_type'] = 'mix'     # Block 4 is mix\n",
    "\n",
    "    # For blocks 2 and 3, set based on distribution\n",
    "    df.loc[(df['block'] == 2) & (df['distribution'] == 'low'), 'block_type'] = 'low'\n",
    "    df.loc[(df['block'] == 2) & (df['distribution'] == 'high'), 'block_type'] = 'high'\n",
    "    df.loc[(df['block'] == 3) & (df['distribution'] == 'low'), 'block_type'] = 'low'\n",
    "    df.loc[(df['block'] == 3) & (df['distribution'] == 'high'), 'block_type'] = 'high'\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(df_participants)):\n",
    "    myCard = df_participants[i]['myCard']\n",
    "    yourCard = df_participants[i]['yourCard']\n",
    "    distributions = df_participants[i]['distribution']\n",
    "    block_type = df_participants[i]['block_type']\n",
    "    risk = df_participants[i]['risk']\n",
    "    \n",
    "    for df_list in [ df_colors_numbers]:\n",
    "        df_list[i]['myCard'] = myCard\n",
    "        df_list[i]['yourCard'] = yourCard\n",
    "        df_list[i]['distribution'] = distributions\n",
    "        df_list[i]['block_type'] = block_type\n",
    "        df_list[i]['risk'] = risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b9c5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_colors_numbers:\n",
    "    df['model_choices'] = df['model_choices'].replace({1: 'arrowup', 0: 'arrowdown'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b12d4f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_colors_numbers:\n",
    "    outcomes = []\n",
    "    for i in range(len(df)):\n",
    "        my = df.loc[i, 'myCard']\n",
    "        your = df.loc[i, 'yourCard']\n",
    "        choice = df.loc[i, 'model_choices']\n",
    "        \n",
    "        if ((my > your and choice == \"arrowup\") or (my < your and choice == \"arrow_down\")):\n",
    "            outcomes.append('win')\n",
    "        else:\n",
    "            outcomes.append('lose')\n",
    "    \n",
    "    df['outcome'] = outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6613e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [os.path.splitext(file)[0].replace(\"task_data_\", \"\")\n",
    "    for file in os.listdir(folder_path_participants) if file.endswith('.xlsx')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "065cd4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Q_table: \n",
      " (9, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "actions = { \"arrowdown\": 0, \"arrowup\": 1}\n",
    "distributions_map = { \"uniform\": 0, \"low\": 1,  \"high\": 2}\n",
    "card_numbers = list(range(1, 10))\n",
    "\n",
    "# policy_table = percentage_matrix \n",
    "\n",
    "Q_table_init = np.random.normal(0, 0.1, (len(card_numbers), len(distributions_map), len(actions)))\n",
    "# having a q-table based on the policies\n",
    "# Q_table_init = policy_table * np.mean(Q_table_init) \n",
    "\n",
    "Q_table = Q_table_init.copy()\n",
    "\n",
    "#############################################################################################\n",
    "# having a q-table that starts with 0! this was not a good initilization so i changed it.\n",
    "# Q_table = np.zeros((len(distributions_map), len(actions)))  # 3 distributions × 2 actions\n",
    "#############################################################################################\n",
    "\n",
    "# print(\"policy: \\n\",np.shape(policy_table))\n",
    "print(\"\\n Q_table: \\n\",np.shape(Q_table))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25b4d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Q_values, beta):\n",
    "    # this part subtracts the maximum q-value in each row it means each state to improve numerical stability.\n",
    "    # because exxponentials of large numbers can lead to overflow errors, so shifting q-values avoids this problem.\n",
    "    \n",
    "    Q_shifted = Q_values - np.max(Q_values, axis=2, keepdims=True)\n",
    "    exps = np.exp(beta * Q_shifted)\n",
    "    sums = np.sum(exps, axis=2, keepdims=True)\n",
    "    new_probs = exps / sums\n",
    "\n",
    "    return new_probs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_dualQ_risk_sensitive(df, alpha_r, alpha_s, beta, eta, Qr_init=None, Qs_init=None):\n",
    "    if Qr_init is None:\n",
    "        Qr_init = Q_table.copy()\n",
    "    if Qs_init is None:\n",
    "        Qs_init = Q_table.copy()\n",
    "\n",
    "    Qr = Qr_init.copy()\n",
    "    Qs = Qs_init.copy()\n",
    "\n",
    "    q_value_pairs = []\n",
    "    choices = []\n",
    "    predicted_probs = []\n",
    "    distributions = []\n",
    "    card_numbers = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        action = actions[row[\"model_choices\"]]\n",
    "        distribution = distributions_map[row[\"distribution\"]]\n",
    "        card_number = row[\"myCard\"] - 1\n",
    "        reward = 0.5 if row[\"outcome\"] == \"win\" else -0.5\n",
    "        risk = row[\"risk\"]  \n",
    "\n",
    "        Q_combined = Qr - eta * Qs\n",
    "        probs = softmax(Q_combined, beta)\n",
    "        predicted_probs.append(probs[card_number][distribution][action])\n",
    "\n",
    "        Qr[card_number][distribution][action] += alpha_r * (reward - Qr[card_number][distribution][action])\n",
    "        Qs[card_number][distribution][action] += alpha_s * (risk - Qs[card_number][distribution][action])\n",
    "\n",
    "        q_value_pairs.append(Q_combined.copy())\n",
    "        choices.append(action)\n",
    "        distributions.append(distribution)\n",
    "        card_numbers.append(card_number)\n",
    "\n",
    "    return np.array(q_value_pairs), np.array(choices), np.array(predicted_probs), np.array(distributions), np.array(card_numbers)\n",
    "\n",
    "\n",
    "\n",
    "def compute_log_likelihood(alpha_r, alpha_s, beta, eta, df_all):\n",
    "    q_values, choices, predicted_probs, distributions, card_numbers = train_dualQ_risk_sensitive(\n",
    "        df_all, alpha_r, alpha_s, beta, eta\n",
    "    )\n",
    "    predicted_probs = np.clip(predicted_probs, 1e-6, 1)\n",
    "    log_likelihood = np.sum(np.log(predicted_probs))\n",
    "    return (alpha_r, alpha_s, beta, eta, log_likelihood)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93538c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 30\n",
    "alpha_min = 0\n",
    "alpha_max = 1\n",
    "beta_min = 0\n",
    "beta_max  = 10\n",
    "eta_min = -1\n",
    "eta_max = 1\n",
    "\n",
    "alpha_r_samples = np.random.uniform(alpha_min, alpha_max + np.finfo(float).eps, num_of_samples)\n",
    "alpha_s_samples = np.random.uniform(alpha_min, alpha_max + np.finfo(float).eps, num_of_samples)\n",
    "beta_samples = np.random.uniform(beta_min, beta_max + np.finfo(float).eps, num_of_samples)\n",
    "eta_samples = np.random.uniform(eta_min, eta_max + np.finfo(float).eps, num_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a0f6378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing participant 1 of 38\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'risk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Nill\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3805, in get_loc\n    return self._engine.get_loc(casted_key)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"index.pyx\", line 167, in pandas._libs.index.IndexEngine.get_loc\n  File \"index.pyx\", line 196, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'risk'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Nill\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\Nill\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Nill\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Nill\\AppData\\Local\\Temp\\2\\ipykernel_33096\\1379002257.py\", line 54, in compute_log_likelihood\n  File \"C:\\Users\\Nill\\AppData\\Local\\Temp\\2\\ipykernel_33096\\1379002257.py\", line 35, in train_dualQ_risk_sensitive\n  File \"c:\\Users\\Nill\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py\", line 1121, in __getitem__\n    return self._get_value(key)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Nill\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py\", line 1237, in _get_value\n    loc = self.index.get_loc(label)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Nill\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3812, in get_loc\n    raise KeyError(key) from err\nKeyError: 'risk'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 22\u001b[0m\n\u001b[0;32m     17\u001b[0m Q_init_participant \u001b[38;5;241m=\u001b[39m Q_table\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     19\u001b[0m df_all \u001b[38;5;241m=\u001b[39m df_all[df_all[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutcome\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mna\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 22\u001b[0m results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloky\u001b[39m\u001b[38;5;124m'\u001b[39m)(\n\u001b[0;32m     23\u001b[0m delayed(compute_log_likelihood)(alpha_r, alpha_s, beta, eta, df_all)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha_r \u001b[38;5;129;01min\u001b[39;00m alpha_r_samples\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha_s \u001b[38;5;129;01min\u001b[39;00m alpha_s_samples\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m beta \u001b[38;5;129;01min\u001b[39;00m beta_samples\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eta \u001b[38;5;129;01min\u001b[39;00m eta_samples)\n\u001b[0;32m     31\u001b[0m alpha_beta_log_likelihood \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     32\u001b[0m best_log_likelihood \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf\n",
      "File \u001b[1;32mc:\\Users\\Nill\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\Nill\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nill\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_error_fast()\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nill\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     error_job\u001b[38;5;241m.\u001b[39mget_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\Nill\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_or_raise()\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Nill\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'risk'"
     ]
    }
   ],
   "source": [
    "BIC_models = []\n",
    "AIC_models = []\n",
    "best_alpha_r_models = []\n",
    "best_alpha_s_models = []\n",
    "best_eta_models = []\n",
    "best_beta_models = []\n",
    "accuracy_models = []\n",
    "precision_models = []\n",
    "sensitivity_recall_models = []\n",
    "specificity_models = []\n",
    "f1_score_models = []\n",
    "mcFadden_r2_models = []\n",
    "r2_models = []\n",
    "\n",
    "for idx, df_all in enumerate(df_colors_numbers):\n",
    "    print(f\"Processing participant {idx + 1} of {len(df_colors_numbers)}\")\n",
    "    Q_init_participant = Q_table.copy()\n",
    "    \n",
    "    df_all = df_all[df_all['outcome'].str.lower() != 'na'].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    results = Parallel(n_jobs=-1, backend='loky')(\n",
    "    delayed(compute_log_likelihood)(alpha_r, alpha_s, beta, eta, df_all)\n",
    "    for alpha_r in alpha_r_samples\n",
    "    for alpha_s in alpha_s_samples\n",
    "    for beta in beta_samples\n",
    "    for eta in eta_samples)\n",
    "\n",
    "\n",
    "\n",
    "    alpha_beta_log_likelihood = {}\n",
    "    best_log_likelihood = -np.inf\n",
    "\n",
    "\n",
    "    for alpha_r, alpha_s, beta, eta, log_likelihood in results:\n",
    "        if log_likelihood > best_log_likelihood:\n",
    "            best_log_likelihood = log_likelihood\n",
    "            best_alpha_r = alpha_r\n",
    "            best_alpha_s = alpha_s\n",
    "            best_beta = beta\n",
    "            best_eta = eta\n",
    "\n",
    "\n",
    "\n",
    "    # model prediction \n",
    "    \n",
    "    q_values, choices, predicted_probs, distributions, card_numbers = train_dualQ_risk_sensitive(df_all, best_alpha_r, best_alpha_s, best_beta, best_eta)\n",
    "\n",
    "    \n",
    "    \n",
    "    predicted_choices = []\n",
    "    for trial in range(len(card_numbers)):\n",
    "        test_action_probs = softmax(q_values[trial], best_beta)\n",
    "        p_arrowup = test_action_probs[card_numbers[trial]][distributions[trial]][actions[\"arrowup\"]]\n",
    "        p_arrow_down = test_action_probs[card_numbers[trial]][distributions[trial]][actions[\"arrowdown\"]]\n",
    "        # choosing 1 or 0 based on the softmax probabilities:\n",
    "        predicted_choices.append(np.random.choice([1, 0], p=[p_arrowup, p_arrow_down]))\n",
    "\n",
    "\n",
    "    # finding out model total reward based on the model's predicted choices\n",
    "    total_reward = [] \n",
    "    for i in range(len(predicted_choices)):\n",
    "        if len(total_reward)> 0:\n",
    "            last_reward = total_reward[-1]  #  the last reward value\n",
    "        else:\n",
    "            last_reward = 10 # initial reward is $10\n",
    "        \n",
    "        if ((df_all.loc[i, 'myCard'] > df_all.loc[i, 'yourCard'] and predicted_choices[i] == 1) or\n",
    "            (df_all.loc[i, 'myCard'] < df_all.loc[i, 'yourCard'] and predicted_choices[i] == 0)):\n",
    "            total_reward.append(last_reward + 0.5)\n",
    "        else:\n",
    "            total_reward.append(last_reward - 0.5)\n",
    "\n",
    "    \n",
    "    \n",
    "    # confusion matrix:\n",
    "    conf_matrix = confusion_matrix(choices, predicted_choices)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()  # unpacking the confusion matrix\n",
    "    # acc\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    # precision: From the ones that we’ve announced them as up/down, which ones are really up/down?\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    # recall or sensitivity : true positive rate\n",
    "    sensitivity_recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    # specificity : true negative rate\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    # f1 Score\n",
    "    f1_score = 2 * (precision * sensitivity_recall) / (precision + sensitivity_recall) if (precision + sensitivity_recall) != 0 else 0\n",
    "\n",
    "    \n",
    "    # bayes information criterion:\n",
    "    n_trials = len(df_all)\n",
    "    k = 4  # number of free parameters: alpha and beta\n",
    "    BIC = k * np.log(n_trials) - 2 * best_log_likelihood # this is BIC formula based on the log lkelihode I found before\n",
    "\n",
    "        # Akaike  information criterion(AIC):\n",
    "    AIC = 2 * k - 2 * best_log_likelihood \n",
    "\n",
    "    # mcFadden r-squared:\n",
    "    p_null = np.mean(choices)  # probability of choosing \"1\" in the dataset\n",
    "    log_likelihood_null = np.sum(choices * np.log(p_null) + (1 - choices) * np.log(1 - p_null))\n",
    "    mcFadden_r2 = 1 - (best_log_likelihood / log_likelihood_null)\n",
    "\n",
    "    # r-squared\n",
    "    r2 = r2_score(choices, predicted_choices)\n",
    "    \n",
    "    \n",
    "    # saving models evaluation variables:\n",
    "    best_alpha_r_models.append(best_alpha_r)\n",
    "    best_alpha_s_models.append(best_alpha_s)\n",
    "    best_eta_models.append(best_eta)\n",
    "    best_beta_models.append(best_beta)\n",
    "    BIC_models.append(BIC)\n",
    "    AIC_models.append(AIC)\n",
    "    accuracy_models.append(accuracy)\n",
    "    precision_models.append(precision)\n",
    "    sensitivity_recall_models.append(sensitivity_recall)\n",
    "    specificity_models.append(specificity)\n",
    "    f1_score_models.append(f1_score)\n",
    "    mcFadden_r2_models.append(mcFadden_r2)\n",
    "    r2_models.append(r2)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6209cd28",
   "metadata": {},
   "source": [
    "# now saving the model evaluation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_evaluation = pd.DataFrame({\n",
    "    \"participants\": participants,\n",
    "    \"best_alpha_r\": best_alpha_r_models,\n",
    "    \"best_alpha_s\": best_alpha_s_models,\n",
    "    \"best_beta\": best_beta_models,\n",
    "    \"best_eta\": best_eta_models,\n",
    "    \"BIC\": BIC_models,\n",
    "    \"AIC\": AIC_models,\n",
    "    \"accuracy\": accuracy_models,\n",
    "    \"precision\": precision_models,\n",
    "    \"sensitivity_recall\": sensitivity_recall_models,\n",
    "    \"specificity\": specificity_models,\n",
    "    \"f1_score\": f1_score_models,\n",
    "    \"mcFadden_r2\": mcFadden_r2_models,\n",
    "    \"r2\": r2_models\n",
    "})\n",
    "\n",
    "file_path = os.path.join(output_dir, \"models_evaluation_risk_dualQ.csv\")\n",
    "df_models_evaluation.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73fb9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f10e808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
