{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398479d4",
   "metadata": {},
   "source": [
    "# param recovery dual Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7001df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# np.random.seed(42)\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.tri as tri\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "import matplotlib.ticker as mticker\n",
    "import itertools\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a1a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"27_RL_agent_TDlearn_output_both_param_recovery\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "folder_path_participants = 'data_risk_added_epileptic'\n",
    "folder_path_colors_numbers = '13_RL_agent_TDlearn_output_risk_dualQ/model_behavior'\n",
    "\n",
    "\n",
    "df_participants = []\n",
    "df_colors_numbers = []\n",
    "\n",
    "\n",
    "def find_matching_csv(folder_path, df_list):\n",
    "            for csv_file in os.listdir(folder_path):\n",
    "                if clean_name in csv_file and csv_file.endswith('.csv'):\n",
    "                    csv_path = os.path.join(folder_path, csv_file)\n",
    "                    df_csv = pd.read_csv(csv_path)\n",
    "                    df_list.append(df_csv)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file_name in os.listdir(folder_path_participants):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path_participants, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[df['outcome'].str.lower() != 'na'].reset_index(drop=True) \n",
    "        df_participants.append(df)\n",
    "\n",
    "        clean_name = file_name.removeprefix(\"task_data_\").removesuffix(\".csv\")\n",
    "        find_matching_csv(folder_path_colors_numbers, df_colors_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67751ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_participants:\n",
    "    df['block_type'] = None\n",
    "\n",
    "    df.loc[df['block'] == 1, 'block_type'] = 'uniform'     # Block 1 is uni\n",
    "    df.loc[df['block'] == 4, 'block_type'] = 'mix'     # Block 4 is mix\n",
    "\n",
    "    # For blocks 2 and 3, set based on distribution\n",
    "    df.loc[(df['block'] == 2) & (df['distribution'] == 'low'), 'block_type'] = 'low'\n",
    "    df.loc[(df['block'] == 2) & (df['distribution'] == 'high'), 'block_type'] = 'high'\n",
    "    df.loc[(df['block'] == 3) & (df['distribution'] == 'low'), 'block_type'] = 'low'\n",
    "    df.loc[(df['block'] == 3) & (df['distribution'] == 'high'), 'block_type'] = 'high'\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(df_participants)):\n",
    "    myCard = df_participants[i]['myCard']\n",
    "    yourCard = df_participants[i]['yourCard']\n",
    "    distributions = df_participants[i]['distribution']\n",
    "    block_type = df_participants[i]['block_type']\n",
    "    risk = df_participants[i]['risk']\n",
    "    \n",
    "    for df_list in [ df_colors_numbers]:\n",
    "        df_list[i]['myCard'] = myCard\n",
    "        df_list[i]['yourCard'] = yourCard\n",
    "        df_list[i]['distribution'] = distributions\n",
    "        df_list[i]['block_type'] = block_type\n",
    "        df_list[i]['risk'] = risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9c5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_colors_numbers:\n",
    "    df['model_choices'] = df['model_choices'].replace({1: 'arrowup', 0: 'arrowdown'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b12d4f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_colors_numbers:\n",
    "    outcomes = []\n",
    "    for i in range(len(df)):\n",
    "        my = df.loc[i, 'myCard']\n",
    "        your = df.loc[i, 'yourCard']\n",
    "        choice = df.loc[i, 'model_choices']\n",
    "        \n",
    "        if ((my > your and choice == \"arrowup\") or (my < your and choice == \"arrowdown\")):\n",
    "            outcomes.append('win')\n",
    "        else:\n",
    "            outcomes.append('lose')\n",
    "    \n",
    "    df['outcome'] = outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6613e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [os.path.splitext(file)[0].replace(\"task_data_\", \"\")\n",
    "    for file in os.listdir(folder_path_participants) if file.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "065cd4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Q_table: \n",
      " (9, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "actions = { \"arrowdown\": 0, \"arrowup\": 1}\n",
    "distributions_map = { \"uniform\": 0, \"low\": 1,  \"high\": 2}\n",
    "card_numbers = list(range(1, 10))\n",
    "\n",
    "# policy_table = percentage_matrix \n",
    "\n",
    "Q_table_init = np.random.normal(0, 0.1, (len(card_numbers), len(distributions_map), len(actions)))\n",
    "# having a q-table based on the policies\n",
    "# Q_table_init = policy_table * np.mean(Q_table_init) \n",
    "\n",
    "Q_table = Q_table_init.copy()\n",
    "\n",
    "#############################################################################################\n",
    "# having a q-table that starts with 0! this was not a good initilization so i changed it.\n",
    "# Q_table = np.zeros((len(distributions_map), len(actions)))  # 3 distributions Ã— 2 actions\n",
    "#############################################################################################\n",
    "\n",
    "# print(\"policy: \\n\",np.shape(policy_table))\n",
    "print(\"\\n Q_table: \\n\",np.shape(Q_table))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fac5cac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_choices</th>\n",
       "      <th>participant_choices</th>\n",
       "      <th>model_total_reward</th>\n",
       "      <th>participant_total_reward</th>\n",
       "      <th>q_val</th>\n",
       "      <th>myCard</th>\n",
       "      <th>yourCard</th>\n",
       "      <th>distribution</th>\n",
       "      <th>block_type</th>\n",
       "      <th>risk</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arrowdown</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>[[[0.09769494872300748, -0.027194159319305494]...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.125</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arrowdown</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>[[[0.09769494872300748, -0.027194159319305494]...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.000</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arrowup</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>[[[0.09769494872300748, -0.027194159319305494]...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>uniform</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.500</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arrowup</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[[[0.09769494872300748, -0.027194159319305494]...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.000</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arrowup</td>\n",
       "      <td>1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>[[[0.09769494872300748, -0.027194159319305494]...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.375</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>arrowup</td>\n",
       "      <td>1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>[[[0.4964520000302995, -0.027194159319305494],...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>high</td>\n",
       "      <td>mix</td>\n",
       "      <td>0.243</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>arrowup</td>\n",
       "      <td>0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>85.5</td>\n",
       "      <td>[[[0.4964520000302995, -0.027194159319305494],...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>high</td>\n",
       "      <td>mix</td>\n",
       "      <td>0.146</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>arrowup</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>[[[0.4964520000302995, -0.027194159319305494],...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>low</td>\n",
       "      <td>mix</td>\n",
       "      <td>0.023</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>arrowup</td>\n",
       "      <td>0</td>\n",
       "      <td>60.5</td>\n",
       "      <td>84.5</td>\n",
       "      <td>[[[0.4964520000302995, -0.027194159319305494],...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>low</td>\n",
       "      <td>mix</td>\n",
       "      <td>0.447</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>arrowdown</td>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>[[[0.4964520000302995, -0.027194159319305494],...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>uniform</td>\n",
       "      <td>mix</td>\n",
       "      <td>0.125</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_choices  participant_choices  model_total_reward  \\\n",
       "0       arrowdown                    0                10.5   \n",
       "1       arrowdown                    1                10.0   \n",
       "2         arrowup                    0                 9.5   \n",
       "3         arrowup                    1                10.0   \n",
       "4         arrowup                    1                10.5   \n",
       "..            ...                  ...                 ...   \n",
       "265       arrowup                    1                61.0   \n",
       "266       arrowup                    0                60.5   \n",
       "267       arrowup                    1                60.0   \n",
       "268       arrowup                    0                60.5   \n",
       "269     arrowdown                    0                61.0   \n",
       "\n",
       "     participant_total_reward  \\\n",
       "0                        10.5   \n",
       "1                        11.0   \n",
       "2                        11.5   \n",
       "3                        12.0   \n",
       "4                        12.5   \n",
       "..                        ...   \n",
       "265                      85.0   \n",
       "266                      85.5   \n",
       "267                      85.0   \n",
       "268                      84.5   \n",
       "269                      85.0   \n",
       "\n",
       "                                                 q_val  myCard  yourCard  \\\n",
       "0    [[[0.09769494872300748, -0.027194159319305494]...       2         7   \n",
       "1    [[[0.09769494872300748, -0.027194159319305494]...       9         4   \n",
       "2    [[[0.09769494872300748, -0.027194159319305494]...       5         6   \n",
       "3    [[[0.09769494872300748, -0.027194159319305494]...       9         1   \n",
       "4    [[[0.09769494872300748, -0.027194159319305494]...       6         4   \n",
       "..                                                 ...     ...       ...   \n",
       "265  [[[0.4964520000302995, -0.027194159319305494],...       8         7   \n",
       "266  [[[0.4964520000302995, -0.027194159319305494],...       4         8   \n",
       "267  [[[0.4964520000302995, -0.027194159319305494],...       8         9   \n",
       "268  [[[0.4964520000302995, -0.027194159319305494],...       3         1   \n",
       "269  [[[0.4964520000302995, -0.027194159319305494],...       2         8   \n",
       "\n",
       "    distribution block_type   risk outcome  \n",
       "0        uniform    uniform  0.125     win  \n",
       "1        uniform    uniform  0.000    lose  \n",
       "2        uniform    uniform  0.500    lose  \n",
       "3        uniform    uniform  0.000     win  \n",
       "4        uniform    uniform  0.375     win  \n",
       "..           ...        ...    ...     ...  \n",
       "265         high        mix  0.243     win  \n",
       "266         high        mix  0.146    lose  \n",
       "267          low        mix  0.023    lose  \n",
       "268          low        mix  0.447     win  \n",
       "269      uniform        mix  0.125     win  \n",
       "\n",
       "[270 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_colors_numbers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25b4d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Q_values, beta):\n",
    "    # this part subtracts the maximum q-value in each row it means each state to improve numerical stability.\n",
    "    # because exxponentials of large numbers can lead to overflow errors, so shifting q-values avoids this problem.\n",
    "    \n",
    "    Q_shifted = Q_values - np.max(Q_values, axis=2, keepdims=True)\n",
    "    exps = np.exp(beta * Q_shifted)\n",
    "    sums = np.sum(exps, axis=2, keepdims=True)\n",
    "    new_probs = exps / sums\n",
    "\n",
    "    return new_probs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_dualQ_risk_sensitive(df, alpha_r, alpha_s, beta, eta, Qr_init=None, Qs_init=None):\n",
    "    if Qr_init is None:\n",
    "        Qr_init = Q_table.copy()\n",
    "    if Qs_init is None:\n",
    "        Qs_init = Q_table.copy()\n",
    "\n",
    "    Qr = Qr_init.copy()\n",
    "    Qs = Qs_init.copy()\n",
    "\n",
    "    q_value_pairs = []\n",
    "    choices = []\n",
    "    predicted_probs = []\n",
    "    distributions = []\n",
    "    card_numbers = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        action = actions[row[\"model_choices\"]]\n",
    "        distribution = distributions_map[row[\"distribution\"]]\n",
    "        card_number = row[\"myCard\"] -1\n",
    "        reward = 0.5 if row[\"outcome\"] == \"win\" else -0.5\n",
    "        risk = row[\"risk\"]  \n",
    "\n",
    "        Q_combined = Qr - eta * Qs\n",
    "        probs = softmax(Q_combined, beta)\n",
    "        predicted_probs.append(probs[card_number][distribution][action])\n",
    "\n",
    "        Qr[card_number][distribution][action] += alpha_r * (reward - Qr[card_number][distribution][action])\n",
    "        Qs[card_number][distribution][action] += alpha_s * (risk - Qs[card_number][distribution][action])\n",
    "\n",
    "        q_value_pairs.append(Q_combined.copy())\n",
    "        choices.append(action)\n",
    "        distributions.append(distribution)\n",
    "        card_numbers.append(card_number)\n",
    "\n",
    "    return np.array(q_value_pairs), np.array(choices), np.array(predicted_probs), np.array(distributions), np.array(card_numbers)\n",
    "\n",
    "\n",
    "\n",
    "def compute_log_likelihood(alpha_r, alpha_s, beta, eta, df_all):\n",
    "    q_values, choices, predicted_probs, distributions, card_numbers = train_dualQ_risk_sensitive(\n",
    "        df_all, alpha_r, alpha_s, beta, eta\n",
    "    )\n",
    "    predicted_probs = np.clip(predicted_probs, 1e-6, 1)\n",
    "    log_likelihood = np.sum(np.log(predicted_probs))\n",
    "    return (alpha_r, alpha_s, beta, eta, log_likelihood)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93538c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 50\n",
    "alpha_min = 0.01\n",
    "alpha_max = 1\n",
    "beta_min = 0.01\n",
    "beta_max  = 8\n",
    "eta_min = -1\n",
    "eta_max = 1\n",
    "\n",
    "alpha_r_samples = np.random.uniform(alpha_min, alpha_max + np.finfo(float).eps, num_of_samples)\n",
    "alpha_s_samples = np.random.uniform(alpha_min, alpha_max + np.finfo(float).eps, num_of_samples)\n",
    "beta_samples = np.random.uniform(beta_min, beta_max + np.finfo(float).eps, num_of_samples)\n",
    "eta_samples = np.random.uniform(eta_min, eta_max + np.finfo(float).eps, num_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a0f6378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing participant 1 of 8\n",
      "0.6333333333333333\n",
      "Processing participant 2 of 8\n",
      "0.6296296296296297\n",
      "Processing participant 3 of 8\n",
      "0.7666666666666667\n",
      "Processing participant 4 of 8\n",
      "0.5703703703703704\n",
      "Processing participant 5 of 8\n",
      "0.6518518518518519\n",
      "Processing participant 6 of 8\n",
      "0.6444444444444445\n",
      "Processing participant 7 of 8\n",
      "0.6259259259259259\n",
      "Processing participant 8 of 8\n",
      "0.5888888888888889\n"
     ]
    }
   ],
   "source": [
    "BIC_models = []\n",
    "AIC_models = []\n",
    "best_alpha_r_models = []\n",
    "best_alpha_s_models = []\n",
    "best_eta_models = []\n",
    "best_beta_models = []\n",
    "accuracy_models = []\n",
    "precision_models = []\n",
    "sensitivity_recall_models = []\n",
    "specificity_models = []\n",
    "f1_score_models = []\n",
    "mcFadden_r2_models = []\n",
    "r2_models = []\n",
    "\n",
    "for idx, df_all in enumerate(df_colors_numbers):\n",
    "    print(f\"Processing participant {idx + 1} of {len(df_colors_numbers)}\")\n",
    "    Q_init_participant = Q_table.copy()\n",
    "    \n",
    "    df_all = df_all[df_all['outcome'].str.lower() != 'na'].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    results = Parallel(n_jobs=-1, backend='loky')(\n",
    "    delayed(compute_log_likelihood)(alpha_r, alpha_s, beta, eta, df_all)\n",
    "    for alpha_r in alpha_r_samples\n",
    "    for alpha_s in alpha_s_samples\n",
    "    for beta in beta_samples\n",
    "    for eta in eta_samples)\n",
    "\n",
    "\n",
    "\n",
    "    alpha_beta_log_likelihood = {}\n",
    "    best_log_likelihood = -np.inf\n",
    "\n",
    "\n",
    "    for alpha_r, alpha_s, beta, eta, log_likelihood in results:\n",
    "        if log_likelihood > best_log_likelihood:\n",
    "            best_log_likelihood = log_likelihood\n",
    "            best_alpha_r = alpha_r\n",
    "            best_alpha_s = alpha_s\n",
    "            best_beta = beta\n",
    "            best_eta = eta\n",
    "\n",
    "\n",
    "\n",
    "    # model prediction \n",
    "    \n",
    "    q_values, choices, predicted_probs, distributions, card_numbers = train_dualQ_risk_sensitive(df_all, best_alpha_r, best_alpha_s, best_beta, best_eta)\n",
    "\n",
    "    \n",
    "    \n",
    "    predicted_choices = []\n",
    "    for trial in range(len(card_numbers)):\n",
    "        test_action_probs = softmax(q_values[trial], best_beta)\n",
    "        p_arrowup = test_action_probs[card_numbers[trial]][distributions[trial]][actions[\"arrowup\"]]\n",
    "        p_arrow_down = test_action_probs[card_numbers[trial]][distributions[trial]][actions[\"arrowdown\"]]\n",
    "        # choosing 1 or 0 based on the softmax probabilities:\n",
    "        predicted_choices.append(np.random.choice([1, 0], p=[p_arrowup, p_arrow_down]))\n",
    "\n",
    "\n",
    "    # finding out model total reward based on the model's predicted choices\n",
    "    total_reward = [] \n",
    "    for i in range(len(predicted_choices)):\n",
    "        if len(total_reward)> 0:\n",
    "            last_reward = total_reward[-1]  #  the last reward value\n",
    "        else:\n",
    "            last_reward = 10 # initial reward is $10\n",
    "        \n",
    "        if ((df_all.loc[i, 'myCard'] > df_all.loc[i, 'yourCard'] and predicted_choices[i] == 1) or\n",
    "            (df_all.loc[i, 'myCard'] < df_all.loc[i, 'yourCard'] and predicted_choices[i] == 0)):\n",
    "            total_reward.append(last_reward + 0.5)\n",
    "        else:\n",
    "            total_reward.append(last_reward - 0.5)\n",
    "\n",
    "    \n",
    "    \n",
    "    # confusion matrix:\n",
    "    conf_matrix = confusion_matrix(choices, predicted_choices)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()  # unpacking the confusion matrix\n",
    "    # acc\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    # precision: From the ones that weâ€™ve announced them as up/down, which ones are really up/down?\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    # recall or sensitivity : true positive rate\n",
    "    sensitivity_recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    # specificity : true negative rate\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    # f1 Score\n",
    "    f1_score = 2 * (precision * sensitivity_recall) / (precision + sensitivity_recall) if (precision + sensitivity_recall) != 0 else 0\n",
    "\n",
    "    \n",
    "    # bayes information criterion:\n",
    "    n_trials = len(df_all)\n",
    "    k = 4  # number of free parameters: alpha and beta\n",
    "    BIC = k * np.log(n_trials) - 2 * best_log_likelihood # this is BIC formula based on the log lkelihode I found before\n",
    "\n",
    "        # Akaike  information criterion(AIC):\n",
    "    AIC = 2 * k - 2 * best_log_likelihood \n",
    "\n",
    "    # mcFadden r-squared:\n",
    "    p_null = np.mean(choices)  # probability of choosing \"1\" in the dataset\n",
    "    log_likelihood_null = np.sum(choices * np.log(p_null) + (1 - choices) * np.log(1 - p_null))\n",
    "    mcFadden_r2 = 1 - (best_log_likelihood / log_likelihood_null)\n",
    "\n",
    "    # r-squared\n",
    "    r2 = r2_score(choices, predicted_choices)\n",
    "    \n",
    "    \n",
    "    # saving models evaluation variables:\n",
    "    best_alpha_r_models.append(best_alpha_r)\n",
    "    best_alpha_s_models.append(best_alpha_s)\n",
    "    best_eta_models.append(best_eta)\n",
    "    best_beta_models.append(best_beta)\n",
    "    BIC_models.append(BIC)\n",
    "    AIC_models.append(AIC)\n",
    "    accuracy_models.append(accuracy)\n",
    "    precision_models.append(precision)\n",
    "    sensitivity_recall_models.append(sensitivity_recall)\n",
    "    specificity_models.append(specificity)\n",
    "    f1_score_models.append(f1_score)\n",
    "    mcFadden_r2_models.append(mcFadden_r2)\n",
    "    r2_models.append(r2)\n",
    "    print(accuracy)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6209cd28",
   "metadata": {},
   "source": [
    "# now saving the model evaluation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fa0bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_evaluation = pd.DataFrame({\n",
    "    \"participants\": participants,\n",
    "    \"best_alpha_r\": best_alpha_r_models,\n",
    "    \"best_alpha_s\": best_alpha_s_models,\n",
    "    \"best_beta\": best_beta_models,\n",
    "    \"best_eta\": best_eta_models,\n",
    "    \"BIC\": BIC_models,\n",
    "    \"AIC\": AIC_models,\n",
    "    \"accuracy\": accuracy_models,\n",
    "    \"precision\": precision_models,\n",
    "    \"sensitivity_recall\": sensitivity_recall_models,\n",
    "    \"specificity\": specificity_models,\n",
    "    \"f1_score\": f1_score_models,\n",
    "    \"mcFadden_r2\": mcFadden_r2_models,\n",
    "    \"r2\": r2_models\n",
    "})\n",
    "\n",
    "file_path = os.path.join(output_dir, \"models_evaluation_risk_dualQ.csv\")\n",
    "df_models_evaluation.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73fb9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f10e808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
