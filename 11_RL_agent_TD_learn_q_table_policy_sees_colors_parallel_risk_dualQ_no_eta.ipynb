{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a6988d",
   "metadata": {},
   "source": [
    "# TD learning; the agent that can see\n",
    "# Remember to check the number of samples for alpha and beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7001df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# np.random.seed(42)\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.tri as tri\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "import matplotlib.ticker as mticker\n",
    "import itertools\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8dd2a",
   "metadata": {},
   "source": [
    "# important directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f147db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'data_risk_added'\n",
    "\n",
    "output_dir_model_evaluation = \"11_RL_agent_TDlearn_output_risk_dualQ_no_eta\"\n",
    "os.makedirs(output_dir_model_evaluation, exist_ok=True)\n",
    "\n",
    "output_dir_plots = os.path.join(output_dir_model_evaluation, \"plots\")\n",
    "os.makedirs(output_dir_plots, exist_ok=True)\n",
    "\n",
    "output_dir_model_behavior = os.path.join(output_dir_model_evaluation, \"model_behavior\")\n",
    "os.makedirs(output_dir_model_behavior, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228a8094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 35 participants.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "arrowRT",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "distribution",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "interTrialInterval",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "outcome",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "myCard",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "yourCard",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "spaceRT",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "totalReward",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "trialIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trialType",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "choice",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "block",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timeoutRepeat",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "risk",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4efe0f3f-0ef5-4c51-a642-b28e949674dd",
       "rows": [
        [
         "0",
         "570",
         "uniform",
         "831",
         "lose",
         "5",
         "2",
         "2209",
         "9.5",
         "0",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.5"
        ],
        [
         "1",
         "1162",
         "uniform",
         "901",
         "lose",
         "4",
         "3",
         "5755",
         "9",
         "1",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.375"
        ],
        [
         "2",
         "355",
         "uniform",
         "939",
         "win",
         "4",
         "6",
         "1209",
         "9.5",
         "2",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.375"
        ],
        [
         "3",
         "1163",
         "uniform",
         "828",
         "win",
         "7",
         "5",
         "1997",
         "10",
         "3",
         "response",
         "arrowup",
         "1",
         "0",
         "0.25"
        ],
        [
         "4",
         "299",
         "uniform",
         "776",
         "win",
         "3",
         "9",
         "1324",
         "10.5",
         "4",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.25"
        ],
        [
         "5",
         "802",
         "uniform",
         "832",
         "win",
         "3",
         "9",
         "1242",
         "11",
         "5",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.25"
        ],
        [
         "6",
         "978",
         "uniform",
         "974",
         "win",
         "2",
         "3",
         "1425",
         "11.5",
         "6",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.125"
        ],
        [
         "7",
         "666",
         "uniform",
         "930",
         "win",
         "9",
         "1",
         "1405",
         "12",
         "7",
         "response",
         "arrowup",
         "1",
         "0",
         "0.0"
        ],
        [
         "8",
         "507",
         "uniform",
         "778",
         "win",
         "1",
         "7",
         "1653",
         "12.5",
         "8",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.0"
        ],
        [
         "9",
         "1058",
         "uniform",
         "973",
         "win",
         "5",
         "6",
         "31909",
         "13",
         "9",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.5"
        ],
        [
         "10",
         "546",
         "uniform",
         "775",
         "win",
         "9",
         "3",
         "1204",
         "13.5",
         "10",
         "response",
         "arrowup",
         "1",
         "0",
         "0.0"
        ],
        [
         "11",
         "507",
         "uniform",
         "855",
         "win",
         "1",
         "4",
         "3015",
         "14",
         "11",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.0"
        ],
        [
         "12",
         "273",
         "uniform",
         "955",
         "win",
         "1",
         "4",
         "2148",
         "14.5",
         "12",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.0"
        ],
        [
         "13",
         "371",
         "uniform",
         "876",
         "win",
         "5",
         "6",
         "1570",
         "15",
         "13",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.5"
        ],
        [
         "14",
         "595",
         "uniform",
         "899",
         "lose",
         "8",
         "4",
         "1846",
         "14.5",
         "14",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.125"
        ],
        [
         "15",
         "756",
         "uniform",
         "992",
         "win",
         "8",
         "4",
         "1038",
         "15",
         "15",
         "response",
         "arrowup",
         "1",
         "0",
         "0.125"
        ],
        [
         "16",
         "811",
         "uniform",
         "981",
         "win",
         "3",
         "2",
         "142018",
         "15.5",
         "16",
         "response",
         "arrowup",
         "1",
         "0",
         "0.25"
        ],
        [
         "17",
         "1082",
         "uniform",
         "924",
         "win",
         "9",
         "1",
         "1246",
         "16",
         "17",
         "response",
         "arrowup",
         "1",
         "0",
         "0.0"
        ],
        [
         "18",
         "577",
         "uniform",
         "758",
         "lose",
         "7",
         "3",
         "2319",
         "15.5",
         "18",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.25"
        ],
        [
         "19",
         "602",
         "uniform",
         "820",
         "win",
         "7",
         "1",
         "3963",
         "16",
         "19",
         "response",
         "arrowup",
         "1",
         "0",
         "0.25"
        ],
        [
         "20",
         "505",
         "uniform",
         "893",
         "win",
         "8",
         "6",
         "21740",
         "16.5",
         "20",
         "response",
         "arrowup",
         "1",
         "0",
         "0.125"
        ],
        [
         "21",
         "1267",
         "uniform",
         "995",
         "lose",
         "6",
         "7",
         "1265",
         "16",
         "21",
         "response",
         "arrowup",
         "1",
         "0",
         "0.375"
        ],
        [
         "22",
         "1803",
         "uniform",
         "819",
         "lose",
         "6",
         "8",
         "1361",
         "15.5",
         "22",
         "response",
         "arrowup",
         "1",
         "0",
         "0.375"
        ],
        [
         "23",
         "953",
         "uniform",
         "786",
         "win",
         "3",
         "8",
         "1539",
         "16",
         "23",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.25"
        ],
        [
         "24",
         "507",
         "uniform",
         "854",
         "win",
         "6",
         "5",
         "1059",
         "16.5",
         "24",
         "response",
         "arrowup",
         "1",
         "0",
         "0.375"
        ],
        [
         "25",
         "507",
         "uniform",
         "784",
         "win",
         "2",
         "7",
         "1337",
         "17",
         "25",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.125"
        ],
        [
         "26",
         "890",
         "uniform",
         "792",
         "lose",
         "6",
         "7",
         "1288",
         "16.5",
         "26",
         "response",
         "arrowup",
         "1",
         "0",
         "0.375"
        ],
        [
         "27",
         "379",
         "uniform",
         "964",
         "win",
         "2",
         "5",
         "1451",
         "17",
         "27",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.125"
        ],
        [
         "28",
         "979",
         "uniform",
         "951",
         "win",
         "8",
         "5",
         "1585",
         "17.5",
         "28",
         "response",
         "arrowup",
         "1",
         "0",
         "0.125"
        ],
        [
         "29",
         "931",
         "uniform",
         "954",
         "win",
         "8",
         "5",
         "1279",
         "18",
         "29",
         "response",
         "arrowup",
         "1",
         "0",
         "0.125"
        ],
        [
         "30",
         "1129",
         "uniform",
         "817",
         "win",
         "3",
         "9",
         "171782",
         "18.5",
         "30",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.25"
        ],
        [
         "31",
         "1283",
         "uniform",
         "857",
         "lose",
         "4",
         "2",
         "1316",
         "18",
         "31",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.375"
        ],
        [
         "32",
         "1217",
         "uniform",
         "974",
         "win",
         "6",
         "2",
         "1348",
         "18.5",
         "32",
         "response",
         "arrowup",
         "1",
         "0",
         "0.375"
        ],
        [
         "33",
         "595",
         "uniform",
         "983",
         "win",
         "1",
         "7",
         "1004",
         "19",
         "33",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.0"
        ],
        [
         "34",
         "835",
         "uniform",
         "875",
         "lose",
         "4",
         "2",
         "1180",
         "18.5",
         "34",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.375"
        ],
        [
         "35",
         "995",
         "uniform",
         "940",
         "lose",
         "7",
         "9",
         "1334",
         "18",
         "35",
         "response",
         "arrowup",
         "1",
         "0",
         "0.25"
        ],
        [
         "36",
         "523",
         "uniform",
         "878",
         "win",
         "9",
         "1",
         "1315",
         "18.5",
         "36",
         "response",
         "arrowup",
         "1",
         "0",
         "0.0"
        ],
        [
         "37",
         "1130",
         "uniform",
         "996",
         "win",
         "5",
         "8",
         "1246",
         "19",
         "37",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.5"
        ],
        [
         "38",
         "553",
         "uniform",
         "954",
         "win",
         "2",
         "8",
         "1116",
         "19.5",
         "38",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.125"
        ],
        [
         "39",
         "1259",
         "uniform",
         "833",
         "win",
         "1",
         "8",
         "1288",
         "20",
         "39",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.0"
        ],
        [
         "40",
         "618",
         "uniform",
         "987",
         "lose",
         "5",
         "4",
         "1320",
         "19.5",
         "40",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.5"
        ],
        [
         "41",
         "914",
         "uniform",
         "841",
         "win",
         "7",
         "6",
         "1540",
         "20",
         "41",
         "response",
         "arrowup",
         "1",
         "0",
         "0.25"
        ],
        [
         "42",
         "834",
         "uniform",
         "918",
         "win",
         "2",
         "3",
         "1850",
         "20.5",
         "42",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.125"
        ],
        [
         "43",
         "882",
         "uniform",
         "792",
         "win",
         "4",
         "9",
         "1799",
         "21",
         "43",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.375"
        ],
        [
         "44",
         "962",
         "uniform",
         "875",
         "win",
         "9",
         "1",
         "1691",
         "21.5",
         "44",
         "response",
         "arrowup",
         "1",
         "0",
         "0.0"
        ],
        [
         "45",
         "827",
         "low",
         "870",
         "win",
         "1",
         "2",
         "1693",
         "22",
         "45",
         "response",
         "arrowdown",
         "2",
         "0",
         "0.0"
        ],
        [
         "46",
         "835",
         "low",
         "845",
         "lose",
         "4",
         "5",
         "1301",
         "21.5",
         "46",
         "response",
         "arrowup",
         "2",
         "0",
         "0.385"
        ],
        [
         "47",
         "523",
         "low",
         "899",
         "win",
         "1",
         "4",
         "1396",
         "22",
         "47",
         "response",
         "arrowdown",
         "2",
         "0",
         "0.0"
        ],
        [
         "48",
         "968",
         "low",
         "989",
         "win",
         "4",
         "1",
         "1414",
         "22.5",
         "48",
         "response",
         "arrowup",
         "2",
         "0",
         "0.385"
        ],
        [
         "49",
         "682",
         "low",
         "935",
         "win",
         "1",
         "2",
         "1696",
         "23",
         "49",
         "response",
         "arrowdown",
         "2",
         "0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 271
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrowRT</th>\n",
       "      <th>distribution</th>\n",
       "      <th>interTrialInterval</th>\n",
       "      <th>outcome</th>\n",
       "      <th>myCard</th>\n",
       "      <th>yourCard</th>\n",
       "      <th>spaceRT</th>\n",
       "      <th>totalReward</th>\n",
       "      <th>trialIndex</th>\n",
       "      <th>trialType</th>\n",
       "      <th>choice</th>\n",
       "      <th>block</th>\n",
       "      <th>timeoutRepeat</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570</td>\n",
       "      <td>uniform</td>\n",
       "      <td>831</td>\n",
       "      <td>lose</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2209</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1162</td>\n",
       "      <td>uniform</td>\n",
       "      <td>901</td>\n",
       "      <td>lose</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5755</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>355</td>\n",
       "      <td>uniform</td>\n",
       "      <td>939</td>\n",
       "      <td>win</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1209</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1163</td>\n",
       "      <td>uniform</td>\n",
       "      <td>828</td>\n",
       "      <td>win</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowup</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>299</td>\n",
       "      <td>uniform</td>\n",
       "      <td>776</td>\n",
       "      <td>win</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1324</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>667</td>\n",
       "      <td>uniform</td>\n",
       "      <td>997</td>\n",
       "      <td>lose</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1290</td>\n",
       "      <td>71</td>\n",
       "      <td>43</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>202</td>\n",
       "      <td>low</td>\n",
       "      <td>944</td>\n",
       "      <td>lose</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1111</td>\n",
       "      <td>70.5</td>\n",
       "      <td>72</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>297</td>\n",
       "      <td>high</td>\n",
       "      <td>833</td>\n",
       "      <td>win</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1049</td>\n",
       "      <td>71</td>\n",
       "      <td>90</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowup</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>1459</td>\n",
       "      <td>high</td>\n",
       "      <td>884</td>\n",
       "      <td>win</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1132</td>\n",
       "      <td>71.5</td>\n",
       "      <td>98</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1123</td>\n",
       "      <td>low</td>\n",
       "      <td>911</td>\n",
       "      <td>win</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1293</td>\n",
       "      <td>72</td>\n",
       "      <td>64</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrowRT distribution  interTrialInterval outcome  myCard  yourCard  \\\n",
       "0       570      uniform                 831    lose       5         2   \n",
       "1      1162      uniform                 901    lose       4         3   \n",
       "2       355      uniform                 939     win       4         6   \n",
       "3      1163      uniform                 828     win       7         5   \n",
       "4       299      uniform                 776     win       3         9   \n",
       "..      ...          ...                 ...     ...     ...       ...   \n",
       "266     667      uniform                 997    lose       5         4   \n",
       "267     202          low                 944    lose       2         1   \n",
       "268     297         high                 833     win       9         6   \n",
       "269    1459         high                 884     win       7         8   \n",
       "270    1123          low                 911     win       3         5   \n",
       "\n",
       "     spaceRT totalReward  trialIndex trialType     choice  block  \\\n",
       "0       2209         9.5           0  response  arrowdown      1   \n",
       "1       5755           9           1  response  arrowdown      1   \n",
       "2       1209         9.5           2  response  arrowdown      1   \n",
       "3       1997          10           3  response    arrowup      1   \n",
       "4       1324        10.5           4  response  arrowdown      1   \n",
       "..       ...         ...         ...       ...        ...    ...   \n",
       "266     1290          71          43  response  arrowdown      4   \n",
       "267     1111        70.5          72  response  arrowdown      4   \n",
       "268     1049          71          90  response    arrowup      4   \n",
       "269     1132        71.5          98  response  arrowdown      4   \n",
       "270     1293          72          64  response  arrowdown      4   \n",
       "\n",
       "     timeoutRepeat   risk  \n",
       "0                0  0.500  \n",
       "1                0  0.375  \n",
       "2                0  0.375  \n",
       "3                0  0.250  \n",
       "4                0  0.250  \n",
       "..             ...    ...  \n",
       "266              0  0.500  \n",
       "267              0  0.243  \n",
       "268              0  0.000  \n",
       "269              0  0.447  \n",
       "270              0  0.447  \n",
       "\n",
       "[271 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = [pd.read_excel(os.path.join(folder_path, file)) for file in os.listdir(folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "n_participant = len(dataframes)\n",
    "print(f\"there are {n_participant} participants.\")\n",
    "dataframes[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e57510",
   "metadata": {},
   "source": [
    "### I want to make participant file name for the model_evaluation.csv and that is I'm gonna take each data name task_data_07_11_2024_17_23_43.xlsx and extract \"07_11_2024_17_23_43\" and this should be the participant name in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "655a0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [os.path.splitext(file)[0].replace(\"task_data_\", \"\")\n",
    "    for file in os.listdir(folder_path) if file.endswith('.xlsx')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec4cf94",
   "metadata": {},
   "source": [
    "# policy initilization for the model\n",
    "now I need to find the prior policy amounts. for that I am going to put the percentage of downarrow and up arrow for each distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc4d584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined = pd.concat(dataframes, ignore_index=True)\n",
    "# df_combined = df_combined[df_combined['outcome'].str.lower() != 'na'].reset_index(drop=True)  \n",
    "\n",
    "# count_df = df_combined.pivot_table(index=\"distribution\", columns=\"choice\", aggfunc=\"size\", fill_value=0)\n",
    "# policy_initialization_df = count_df.div(count_df.sum(axis=1), axis=0)\n",
    "# policy_initialization_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "065cd4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = { \"arrowdown\": 0, \"arrowup\": 1}\n",
    "distributions_map = { \"uniform\": 0, \"low\": 1,  \"high\": 2}\n",
    "\n",
    "# policy_table = policy_initialization_df.rename(index=distributions_map, columns=actions).sort_index().to_numpy()\n",
    "\n",
    "Q_table_init = np.random.normal(0, 0.1, (len(distributions_map), len(actions)))\n",
    "\n",
    "\n",
    "# having a q-table based on the policies\n",
    "# Q_table_init = policy_table * np.mean(Q_table_init) \n",
    "Q_table = Q_table_init.copy()\n",
    "\n",
    "# having a q-table that starts with 0!\n",
    "# Q_table = np.zeros((len(distributions_map), len(actions)))  # 3 distributions × 2 actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25b4d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Q_values, beta):    \n",
    "    # this part subtracts the maximum q-value in each row it means each state to improve numerical stability.\n",
    "    # because exxponentials of large numbers can lead to overflow errors, so shifting q-values avoids this problem.\n",
    "    \n",
    "    Q_shifted = Q_values - np.max(Q_values, axis=1, keepdims=True)\n",
    "    exps = np.exp(beta * Q_shifted)\n",
    "    sums = np.sum(exps, axis=1, keepdims=True)\n",
    "    new_probs = exps / sums\n",
    "\n",
    "    return new_probs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_dualQ_risk_sensitive(df, alpha_r, alpha_s, beta, Qr_init=None, Qs_init=None):\n",
    "    if Qr_init is None:\n",
    "        Qr_init = Q_table.copy()\n",
    "    if Qs_init is None:\n",
    "        Qs_init = Q_table.copy()\n",
    "\n",
    "    Qr = Qr_init.copy()\n",
    "    Qs = Qs_init.copy()\n",
    "\n",
    "    q_value_pairs = []\n",
    "    choices = []\n",
    "    predicted_probs = []\n",
    "    distributions = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        action = actions[row[\"choice\"]]\n",
    "        distribution = distributions_map[row[\"distribution\"]]\n",
    "        reward = 0.5 if row[\"outcome\"] == \"win\" else -0.5\n",
    "        risk = row[\"risk\"]  \n",
    "\n",
    "        Q_combined = Qr - ((alpha_s - alpha_r)/(alpha_s + alpha_r)) * Qs\n",
    "        probs = softmax(Q_combined, beta)\n",
    "        predicted_probs.append(probs[distribution][action])\n",
    "\n",
    "        Qr[distribution][action] += alpha_r * (reward - Qr[distribution][action])\n",
    "        Qs[distribution][action] += alpha_s * (risk - Qs[distribution][action])\n",
    "\n",
    "        q_value_pairs.append(Q_combined.copy())\n",
    "        choices.append(action)\n",
    "        distributions.append(distribution)\n",
    "\n",
    "    return np.array(q_value_pairs), np.array(choices), np.array(predicted_probs), np.array(distributions)\n",
    "\n",
    "\n",
    "\n",
    "def compute_log_likelihood(alpha_r, alpha_s, beta, df_all):\n",
    "    q_values, choices, predicted_probs, distributions = train_dualQ_risk_sensitive(\n",
    "        df_all, alpha_r, alpha_s, beta\n",
    "    )\n",
    "    predicted_probs = np.clip(predicted_probs, 1e-6, 1)\n",
    "    log_likelihood = np.sum(np.log(predicted_probs))\n",
    "    return (alpha_r, alpha_s, beta, log_likelihood)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 100\n",
    "alpha_min = 0\n",
    "alpha_max = 1\n",
    "beta_min = 0\n",
    "beta_max  = 10\n",
    "\n",
    "\n",
    "alpha_r_samples = np.random.uniform(alpha_min, alpha_max + np.finfo(float).eps, num_of_samples)\n",
    "alpha_s_samples = np.random.uniform(alpha_min, alpha_max + np.finfo(float).eps, num_of_samples)\n",
    "beta_samples = np.random.uniform(beta_min, beta_max + np.finfo(float).eps, num_of_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a0f6378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_18_11_2024_13_31_43.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_22_03_2025_00_10_37.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_14_11_2024_21_46_47.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_18_03_2025_20_59_56.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_13_11_2024_14_45_52.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_19_11_2024_14_28_20.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_18_11_2024_15_43_17.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_26_03_2025_16_21_25.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_19_11_2024_17_03_01.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_11_11_2024_16_46_44.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_20_11_2024_16_58_23.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_25_11_2024_18_41_38.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_20_11_2024_15_14_56.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_25_11_2024_20_12_41.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_28_11_2024_12_21_16.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_13_11_2024_10_46_21.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_25_11_2024_12_11_10.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_18_03_2025_13_12_31.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_07_11_2024_17_23_43.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_28_11_2024_22_38_25.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_19_11_2024_19_42_32.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_26_11_2024_10_53_23.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_20_11_2024_15_41_35.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_20_11_2024_14_51_17.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_08_11_2024_13_03_29.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_25_11_2024_07_37_11.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_22_11_2024_15_19_47.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_17_11_2024_15_25_39.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_22_11_2024_12_34_30.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_26_11_2024_14_31_40.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_22_11_2024_14_36_42.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_17_11_2024_23_57_47.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_15_11_2024_11_43_48.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_12_11_2024_00_15_17.pdf\n",
      "saved: 11_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_20_11_2024_09_23_29.pdf\n"
     ]
    }
   ],
   "source": [
    "BIC_models = []\n",
    "AIC_models = []\n",
    "best_alpha_r_models = []\n",
    "best_alpha_s_models = []\n",
    "best_beta_models = []\n",
    "accuracy_models = []\n",
    "precision_models = []\n",
    "sensitivity_recall_models = []\n",
    "specificity_models = []\n",
    "f1_score_models = []\n",
    "mcFadden_r2_models = []\n",
    "r2_models = []\n",
    "\n",
    "for idx, df_all in enumerate(dataframes):\n",
    "    \n",
    "    df_all = df_all[df_all['outcome'].str.lower() != 'na'].reset_index(drop=True)  \n",
    "\n",
    "    \n",
    "    Q_init_participant = Q_table.copy()\n",
    "\n",
    "    best_alpha, best_beta = None, None\n",
    "    best_log_likelihood = -np.inf\n",
    "\n",
    "\n",
    "    alpha_beta_log_likelihood = {}\n",
    "\n",
    "\n",
    "    # finding alpha beta in parallel way\n",
    "    results = Parallel(n_jobs=-1, backend='loky')(\n",
    "    delayed(compute_log_likelihood)(alpha_r, alpha_s, beta, df_all)\n",
    "    for alpha_r in alpha_r_samples\n",
    "    for alpha_s in alpha_s_samples\n",
    "    for beta in beta_samples)\n",
    "\n",
    "\n",
    "    alpha_beta_log_likelihood = {}\n",
    "    best_log_likelihood = -np.inf\n",
    "\n",
    "\n",
    "    for alpha_r, alpha_s, beta,  log_likelihood in results:\n",
    "        if log_likelihood > best_log_likelihood:\n",
    "            best_log_likelihood = log_likelihood\n",
    "            best_alpha_r = alpha_r\n",
    "            best_alpha_s = alpha_s\n",
    "            best_beta = beta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #  model prediction \n",
    "    \n",
    "    # this is not model's choices, it's human choices, you need to save model predicted choices using q-values\n",
    "    q_values, choices, predicted_probs, distributions  = train_dualQ_risk_sensitive(df_all, best_alpha_r, best_alpha_s, best_beta)\n",
    "    # now we need to find out the predicted choices of the model:\n",
    "    \n",
    "\n",
    "    ###################################################################################################################\n",
    "    # now we need to find out the predicted choices of the model:\n",
    "    # predicted_choices = []\n",
    "    # for trial in range(len(distributions)):  \n",
    "    #     if q_values[trial][distributions[trial]][actions[\"arrowup\"]] > q_values[trial][distributions[trial]][actions[\"arrowdown\"]]:\n",
    "    #         predicted_choices.append(1)\n",
    "    #     else:\n",
    "    #         predicted_choices.append(0)\n",
    "\n",
    "\n",
    "    # the code above was not correct!! because we're using softmax policy in the training process but here we're ONLY\n",
    "    # using greedy way of choosing best actions! so here is the corect code:\n",
    "    ###################################################################################################################\n",
    "\n",
    "    predicted_choices = []\n",
    "    for trial in range(len(distributions)):  \n",
    "        test_action_probs = softmax(q_values[trial], best_beta)\n",
    "        p_arrowup = test_action_probs[distributions[trial]][actions[\"arrowup\"]]\n",
    "        p_arrow_down = test_action_probs[distributions[trial]][actions[\"arrowdown\"]]\n",
    "        # choosing 1 or 0 based on the softmax probabilities:\n",
    "        predicted_choices.append(np.random.choice([1, 0], p=[p_arrowup, p_arrow_down]))\n",
    "\n",
    "\n",
    "    # finding out model total reward based on the model's predicted choices\n",
    "    total_reward = [] \n",
    "    for i in range(len(predicted_choices)):\n",
    "        if len(total_reward)> 0:\n",
    "            last_reward = total_reward[-1]  #  the last reward value\n",
    "        else:\n",
    "            last_reward = 10 # initial reward is $10\n",
    "        \n",
    "        if ((df_all.loc[i, 'myCard'] > df_all.loc[i, 'yourCard'] and predicted_choices[i] == 1) or\n",
    "            (df_all.loc[i, 'myCard'] < df_all.loc[i, 'yourCard'] and predicted_choices[i] == 0)):\n",
    "            total_reward.append(last_reward + 0.5)\n",
    "        else:\n",
    "            total_reward.append(last_reward - 0.5)\n",
    "    \n",
    "    \n",
    "       # confusion matrix:\n",
    "    conf_matrix = confusion_matrix(choices, predicted_choices)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()  # unpacking the confusion matrix\n",
    "    # acc\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    # precision: From the ones that we’ve announced them as up/down, which ones are really up/down?\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    # recall or sensitivity : true positive rate\n",
    "    sensitivity_recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    # specificity : true negative rate\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    # f1 Score\n",
    "    f1_score = 2 * (precision * sensitivity_recall) / (precision + sensitivity_recall) if (precision + sensitivity_recall) != 0 else 0\n",
    "\n",
    "    \n",
    "    # bayes information criterion:\n",
    "    n_trials = len(df_all)\n",
    "    k = 3  # number of free parameters: alpha and beta\n",
    "    BIC = k * np.log(n_trials) - 2 * best_log_likelihood # this is BIC formula based on the log lkelihode I found before\n",
    "\n",
    "\n",
    "    # Akaike  information criterion(AIC):\n",
    "    AIC = 2 * k - 2 * best_log_likelihood \n",
    "\n",
    "    # mcFadden r-squared:\n",
    "    p_null = np.mean(choices)  # probability of choosing \"1\" in the dataset\n",
    "    log_likelihood_null = np.sum(choices * np.log(p_null) + (1 - choices) * np.log(1 - p_null))\n",
    "    mcFadden_r2 = 1 - (best_log_likelihood / log_likelihood_null)\n",
    "\n",
    "    # r-squared\n",
    "    r2 = r2_score(choices, predicted_choices)\n",
    "    \n",
    " \n",
    "    # saving models evaluation variables:\n",
    "    best_alpha_r_models.append(best_alpha_r)\n",
    "    best_alpha_s_models.append(best_alpha_s)\n",
    "    best_beta_models.append(best_beta)\n",
    "    BIC_models.append(BIC)\n",
    "    AIC_models.append(AIC)\n",
    "    accuracy_models.append(accuracy)\n",
    "    precision_models.append(precision)\n",
    "    sensitivity_recall_models.append(sensitivity_recall)\n",
    "    specificity_models.append(specificity)\n",
    "    f1_score_models.append(f1_score)\n",
    "    mcFadden_r2_models.append(mcFadden_r2)\n",
    "    r2_models.append(r2)\n",
    "\n",
    "  \n",
    "    ###########################################################################################\n",
    "    ## visulization\n",
    "    ###########################################################################################\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    heatmap_cmap_color = mcolors.LinearSegmentedColormap.from_list(\"warm_red\", [\"#fff5e6\", \"#ff5733\"])\n",
    "    sns.heatmap(\n",
    "        conf_matrix, annot=True, fmt=\"d\", cmap=heatmap_cmap_color,\n",
    "        xticklabels=[\"arrowdown\", \"arrowup\"], \n",
    "        yticklabels=[\"arrowdown\", \"arrowup\"], \n",
    "        ax=ax, \n",
    "        cbar=False\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"prediction\", fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(\"true label\", fontsize=14, fontweight='bold')\n",
    "    ax.set_title(\"confusion matrix\", fontsize=16, fontweight='bold')\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "\n",
    "#############################################\n",
    "    # saving figures\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.9]) \n",
    "    fig.suptitle(f'participant {idx}', fontsize=18, fontweight='bold', y=0.95)\n",
    "\n",
    "    filename = os.path.join(output_dir_plots, f\"plot_{participants[idx]}.pdf\")\n",
    "    plt.savefig(filename, format='pdf')\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"saved: {filename}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "    # saving model behavior\n",
    "    q_values_reshaped = [q_values[i].tolist() for i in range(n_trials)]  # convert each (9,3,2) array into a list format\n",
    "\n",
    "    # print(\"Shape of predicted_choices:\", np.shape(predicted_choices))\n",
    "    # print(\"Shape of choices:\", np.shape(choices))\n",
    "    # print(\"Shape of total_reward:\", np.shape(total_reward))\n",
    "    # print(\"Shape of q_values_reshaped:\", np.shape(q_values_reshaped))\n",
    "\n",
    "    df_model_behavior = pd.DataFrame({\n",
    "        \"model_choices\": predicted_choices,\n",
    "        \"participant_choices\": choices,\n",
    "        \"model_total_reward\": total_reward,\n",
    "        \"participant_total_reward\": df_all[\"totalReward\"],\n",
    "        \"q_val\": q_values_reshaped  \n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    file_path = os.path.join(output_dir_model_behavior, f\"model_behavior_{participants[idx]}.csv\")\n",
    "    df_model_behavior.to_csv(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf9815f",
   "metadata": {},
   "source": [
    "# now saving the model evaluation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa0bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_evaluation = pd.DataFrame({\n",
    "    \"participants\": participants,\n",
    "    \"best_alpha_r\": best_alpha_r_models,\n",
    "    \"best_alpha_s\": best_alpha_s_models,\n",
    "    \"best_beta\": best_beta_models,\n",
    "    \"BIC\": BIC_models,\n",
    "    \"AIC\": AIC_models,\n",
    "    \"accuracy\": accuracy_models,\n",
    "    \"precision\": precision_models,\n",
    "    \"sensitivity_recall\": sensitivity_recall_models,\n",
    "    \"specificity\": specificity_models,\n",
    "    \"f1_score\": f1_score_models,\n",
    "    \"mcFadden_r2\": mcFadden_r2_models,\n",
    "    \"r2\": r2_models\n",
    "})\n",
    "\n",
    "file_path = os.path.join(output_dir_model_evaluation, \"models_evaluation.csv\")\n",
    "df_models_evaluation.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b094a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74688048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bebc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acf4011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
